{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Pa9oTbZXovX",
        "outputId": "bf21750a-d639-47c4-e9fb-71a7c84224d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Dec  9 04:46:12 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P0    32W /  70W |   1338MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "Not using a high-RAM runtime\n"
          ]
        }
      ],
      "source": [
        "    base = 'gdrive/MyDrive/vocr/'\n",
        "\n",
        "#Runtime Info\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrnKX9eIGzK2",
        "outputId": "723daeb9-6759-4449-9250-aa22ea1c9177"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Unzipping...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "#setup\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!rm -rf Partitioned-Organic-Data-Split\n",
        "print(\"Unzipping...\")\n",
        "!unzip {base}Partitioned-Organic-Data-Split.zip>/dev/null\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "CATuG8sOViYQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random as rn\n",
        "import tensorflow as tf\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "np.random.seed(0)\n",
        "rn.seed(0)\n",
        "tf.random.set_seed(0)\n",
        "from datetime import datetime\n",
        "from glob import glob\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.combine import SMOTEENN\n",
        "from random import randint\n",
        "import sklearn\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import f1_score, confusion_matrix, precision_recall_fscore_support\n",
        "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.applications import MobileNetV3Small, MobileNetV3Large, ResNet50V2\n",
        "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger\n",
        "from tensorflow.keras.layers import Dense, add, Dropout, Flatten, Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, BatchNormalization, Activation, Input, Concatenate, Cropping2D, ActivityRegularization, RandomBrightness, RandomContrast, RandomCrop, RandomFlip, RandomHeight, RandomRotation, RandomTranslation, RandomWidth, RandomZoom\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import codecs\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import time\n",
        "from google.colab import runtime\n",
        "from scipy.io import loadmat\n",
        "import multiprocessing\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "tf.get_logger().setLevel('ERROR')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Ny6SVPtmYFHl"
      },
      "outputs": [],
      "source": [
        "# Util functions\n",
        "def log(message):\n",
        "\tprint(message)\n",
        "\tfile = codecs.open(base+\"log.txt\", \"a\", \"cp1252\", \"replace\")\n",
        "\tprint(message, file=file)\n",
        "\n",
        "def load_img(path, label):\n",
        "\timg = tf.io.read_file(path)\n",
        "\timg = tf.io.decode_png(img, channels=3)\n",
        "\timg = tf.image.resize(img, (224,224))\n",
        "\treturn img, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "mxjjkWeKYqsQ"
      },
      "outputs": [],
      "source": [
        "class MetricCallback(Callback):\n",
        "\tdef __init__(self, x, y, k=0, patience=0, restore_best=True):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.x = x\n",
        "\t\tself.y = y\n",
        "\t\tself.k=k\n",
        "\t\tself.best_score = 0.0\n",
        "\t\tself.best_epoch = 0\n",
        "\t\tself.best_weights = None\n",
        "\t\tself.patience = patience\n",
        "\t\tself.restore_best = restore_best\n",
        "\n",
        "\tdef restore(self):\n",
        "\t\tself.model.set_weights(self.best_weights)\n",
        "\n",
        "\tdef on_epoch_end(self, epoch, logs={}):\n",
        "\t\tpreds = self.model.predict(self.x)\n",
        "\t\tfinal = f1_score(self.y.argmax(-1), preds.argmax(-1), average='micro')\n",
        "\t\tif final>self.best_score:\n",
        "\t\t\tfor f in glob(\"*.h5\"): os.remove(f)\n",
        "\t\t\tself.model.save(f\"model {self.k+1} {epoch+1} f{final:.3f}.h5\")\n",
        "\t\t\t!rm {base}*.h5\n",
        "\t\t\t!cp *.h5 {base}\n",
        "\t\t\tlog(f\"{epoch+1} Best Score: improved from {self.best_score:.3f} to {final:.3f}\")\n",
        "\t\t\tself.best_score = final\n",
        "\t\t\tself.best_epoch = epoch\n",
        "\t\t\tself.best_weights = self.model.get_weights()\n",
        "\t\telse: log(f\"{epoch+1} Score: {final:.3f}, Best epoch: {self.best_epoch+1}, {self.best_score:.3f}\")\n",
        "\n",
        "\t\tif self.patience>0 and epoch-self.best_epoch >= self.patience:\n",
        "\t\t\tprint(\"Stopping...\")\n",
        "\t\t\tself.stopped_epoch = epoch\n",
        "\t\t\tself.model.stop_training = True\n",
        "\t\t\tif self.restore_best: self.restore()\n",
        "\t\t\treturn\n",
        "\n",
        "\t\tif not epoch == self.best_epoch and (epoch-self.best_epoch)%int(self.patience/2) == 0:\n",
        "\t\t\told_lr = float(tf.keras.backend.get_value(self.model.optimizer.lr))\n",
        "\t\t\tnew_lr = old_lr * 0.1\n",
        "\t\t\ttf.keras.backend.set_value(self.model.optimizer.lr, new_lr)\n",
        "\t\t\tself.restore()\n",
        "\t\t\tlog(f\"Reducing learning rate from {old_lr} to {new_lr}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "U7Qz6pFhZDGo"
      },
      "outputs": [],
      "source": [
        "# Model\n",
        "def describe(model):\n",
        "\tfor i, layer in enumerate(model.layers):\n",
        "\t\tif layer.trainable: print(i, layer.name, layer.trainable, layer.dtype_policy, layer.dtype, layer.input_shape, layer.output_shape)\n",
        "\t\tif hasattr(layer, \"layers\"): describe(layer)\n",
        "\n",
        "def create_model(input_shape, output_shape):\n",
        "\tdata_augmentation = Sequential([\n",
        "\t\tRandomBrightness(0.2),\n",
        "\t\tRandomContrast(0.2),\n",
        "\t\tRandomFlip(),\n",
        "\t\tRandomRotation(0.2),\n",
        "\t\tRandomTranslation(0.2, 0.2),\n",
        "\t\tRandomZoom(0.2, 0.2)\n",
        "\t])\n",
        "\tbase_model = MobileNetV3Small(include_top=False, input_shape=input_shape, weights='imagenet', pooling=\"avg\")\n",
        "\tbase_model.trainable = False\n",
        "\tinputs = Input(shape=input_shape)\n",
        "\tx = data_augmentation(inputs)\n",
        "\tx = base_model(x, training=False)\n",
        "\tx = Dense(256)(x)\n",
        "\tx = BatchNormalization()(x)\n",
        "\tx = Activation(\"relu\")(x)\n",
        "\tx = Dropout(0.2)(x)\n",
        "\tx = Dense(output_shape)(x)\n",
        "\toutputs = Activation('softmax', dtype='float32')(x)\n",
        "\tmodel=Model(inputs=inputs, outputs=outputs)\n",
        "\tmodel.compile(optimizer=Adam(1e-3), loss='CategoricalCrossentropy',metrics=['accuracy'])\n",
        "\tdescribe(model)\n",
        "\tprint(model.summary())\n",
        "\treturn model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "vaQJs_5pG-Fi"
      },
      "outputs": [],
      "source": [
        "#Imblearn\n",
        "def balance(x, y):\n",
        "\tprint(\"Balancing samples...\")\n",
        "\tros = RandomOverSampler()\n",
        "\tx, y = ros.fit_resample(x.reshape(-1,1), y)\n",
        "\t# Can't use synthetic for memory limitation\n",
        "\t#smote_enn = SMOTEENN(random_state=0)\n",
        "\t#x, y = smote_enn.fit_resample(x, y)\n",
        "\tx = x.reshape(-1)\n",
        "\tu, c = np.unique(y, return_counts=True)\n",
        "\tnames = [le.classes_[l] for l in u]\n",
        "\tdist = list(zip(names, c))\n",
        "\tdist = sorted(dist, key = lambda x: x[1])\n",
        "\tprint(\"Distribution after over sampling:\", dist)\n",
        "\treturn x, y\n",
        "\t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8d8jD0GPspR",
        "outputId": "3b6cbd0d-6d8f-4bba-d244-79b57cb2e302"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting at: 12/09/2022, 05:01:10\n",
            "Size: (224, 224, 3), batch_size: 32, k_fold: 0\n",
            "Tensorflow: 2.9.2\n",
            "SKLearn: 1.0.2\n"
          ]
        }
      ],
      "source": [
        "size = (224, 224, 3)\n",
        "batch_size = 32\n",
        "k=0\n",
        "t_start = time.time()\n",
        "now = datetime.now()\n",
        "date_time = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
        "log(f\"Starting at: {date_time}\")\n",
        "log(f\"Size: {size}, batch_size: {batch_size}, k_fold: {k}\")\n",
        "log(f\"Tensorflow: {tf.version.VERSION}\")\n",
        "log(f\"SKLearn: {sklearn.__version__}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ex6JzOpffOH",
        "outputId": "852aa718-d733-4fff-a0a0-1b839ef36ca2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train: (143116,), y_train:(143116, 16), x_test: (19086,), y_test: (19086, 16)\n"
          ]
        }
      ],
      "source": [
        "train = loadmat(\"Partitioned-Organic-Data-Split/organic-training.mat\")\n",
        "x_train = train['trainingImages'].flatten()\n",
        "x_train = [x[0][x[0].index(\"Partitioned\"):] for x in x_train]\n",
        "x_train = np.array(x_train)\n",
        "y_train = train['labels'].flatten().astype(int)\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "weight = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "weight = dict(zip(np.unique(y_train), weight))\n",
        "y_train= to_categorical(y_train)\n",
        "\n",
        "validation = loadmat(\"Partitioned-Organic-Data-Split/organic-validation.mat\")\n",
        "x_validation = validation['trainingImages'].flatten()\n",
        "x_validation = [x[0][x[0].index(\"Partitioned\"):] for x in x_validation]\n",
        "x_validation = np.array(x_validation)\n",
        "y_validation = validation['labels'].flatten().astype(int)\n",
        "y_validation = le.transform(y_validation)\n",
        "y_validation = to_categorical(y_validation)\n",
        "\n",
        "test = loadmat(\"Partitioned-Organic-Data-Split/organic-test.mat\")\n",
        "x_test = test['trainingImages'].flatten()\n",
        "x_test = [x[0][x[0].index(\"Partitioned\"):] for x in x_test]\n",
        "x_test = np.array(x_test)\n",
        "y_test = test['labels'].flatten().astype(int)\n",
        "y_test = le.transform(y_test)\n",
        "y_test = to_categorical(y_test)\n",
        "log(f\"x_train: {x_train.shape}, y_train:{y_train.shape}, x_test: {x_test.shape}, y_test: {y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvfFhU5Ie8cB",
        "outputId": "b46e673e-3080-41b4-c165-b498923d2092"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training fold 0...\n",
            "0 input_24 True <Policy \"float32\"> float32 [(None, 224, 224, 3)] [(None, 224, 224, 3)]\n",
            "1 sequential_11 True <Policy \"mixed_float16\"> float32 (None, 224, 224, 3) (None, 224, 224, 3)\n",
            "0 random_brightness_11 True <Policy \"mixed_float16\"> float32 (None, 224, 224, 3) (None, 224, 224, 3)\n",
            "1 random_contrast_11 True <Policy \"mixed_float16\"> float32 (None, 224, 224, 3) (None, 224, 224, 3)\n",
            "2 random_flip_11 True <Policy \"mixed_float16\"> float32 (None, 224, 224, 3) (None, 224, 224, 3)\n",
            "3 random_rotation_11 True <Policy \"mixed_float16\"> float32 (None, 224, 224, 3) (None, 224, 224, 3)\n",
            "4 random_translation_11 True <Policy \"mixed_float16\"> float32 (None, 224, 224, 3) (None, 224, 224, 3)\n",
            "5 random_zoom_11 True <Policy \"mixed_float16\"> float32 (None, 224, 224, 3) (None, 224, 224, 3)\n",
            "3 dense_22 True <Policy \"mixed_float16\"> float32 (None, 576) (None, 256)\n",
            "4 batch_normalization_11 True <Policy \"mixed_float16\"> float32 (None, 256) (None, 256)\n",
            "5 activation_15 True <Policy \"mixed_float16\"> float32 (None, 256) (None, 256)\n",
            "6 dropout_11 True <Policy \"mixed_float16\"> float32 (None, 256) (None, 256)\n",
            "7 dense_23 True <Policy \"mixed_float16\"> float32 (None, 256) (None, 16)\n",
            "8 activation_16 True <Policy \"float32\"> float32 (None, 16) (None, 16)\n",
            "Model: \"model_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_24 (InputLayer)       [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " sequential_11 (Sequential)  (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " MobilenetV3small (Functiona  (None, 576)              939120    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 256)               147712    \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 256)              1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_15 (Activation)  (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 16)                4112      \n",
            "                                                                 \n",
            " activation_16 (Activation)  (None, 16)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,091,968\n",
            "Trainable params: 152,336\n",
            "Non-trainable params: 939,632\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/1000\n",
            " 336/4473 [=>............................] - ETA: 24:35 - loss: 0.9598 - accuracy: 0.6952"
          ]
        }
      ],
      "source": [
        "#Train\n",
        "log(f\"Training fold {k}...\")\n",
        "model = create_model(size, y_train.shape[1])\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_ds= train_ds.shuffle(x_train.shape[0]).map(load_img, num_parallel_calls=batch_size).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "validation_ds = tf.data.Dataset.from_tensor_slices((x_validation, y_validation))\n",
        "validation_ds= validation_ds.map(load_img, num_parallel_calls=batch_size).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "mc = MetricCallback(validation_ds, y_validation, patience=50)\n",
        "logger = CSVLogger(base+'train.csv')\n",
        "callbacks = [mc, logger]\n",
        "history = model.fit(train_ds, validation_data=validation_ds, epochs=1000, callbacks =callbacks, workers=multiprocessing.cpu_count(), use_multiprocessing=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrYuVHAzfBSe"
      },
      "outputs": [],
      "source": [
        "#Predict\n",
        "mc.restore()\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "test_ds= test_ds.map(load_img, num_parallel_calls=batch_size).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "preds = model.predict(test_ds)\n",
        "score = precision_recall_fscore_support(y_test.argmax(-1), preds.argmax(-1), average='micro')\n",
        "print(f\"Micro Precision: {score[0]:.2f}, Recall: {score[1]:.2f}, F1: {score[2]:.2f}\")\n",
        "score = precision_recall_fscore_support(y_test.argmax(-1), preds.argmax(-1), average='weighted')\n",
        "print(f\"Weighted Precision: {score[0]:.2f}, Recall: {score[1]:.2f}, F1: {score[2]:.2f}\")\n",
        "score = precision_recall_fscore_support(y_test.argmax(-1), preds.argmax(-1), average='macro')\n",
        "print(f\"Macro Precision: {score[0]:.2f}, Recall: {score[1]:.2f}, F1: {score[2]:.2f}\")\n",
        "matrix = confusion_matrix(y_test.argmax(-1), preds.argmax(-1))\n",
        "print(\"Confusion Matrix:\")\n",
        "for i,m in enumerate(matrix):\n",
        "  row = [(le.classes_[j], k) for j, k in enumerate(m) if k>0]\n",
        "  print(i, le.classes_[i], row)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#End\n",
        "now = datetime.now()\n",
        "date_time = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
        "log(f\"Ending at: {date_time}\")\n",
        "t_finish = time.time()\n",
        "total_time = (t_finish-t_start)/60\n",
        "log(f\"It took {total_time:.2f} minutes\")\n",
        "time.sleep(1)\n",
        "#runtime.unassign()"
      ],
      "metadata": {
        "id": "0qnKz5UYol16"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}