{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Pa9oTbZXovX",
        "outputId": "caf280ff-8909-4491-8107-70367a7301ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Dec  5 13:27:06 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P0    29W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "Not using a high-RAM runtime\n"
          ]
        }
      ],
      "source": [
        "    base = 'gdrive/MyDrive/ppat/chi_train/'\n",
        "\n",
        "#Runtime Info\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrnKX9eIGzK2",
        "outputId": "6166b610-12ba-4b39-aa8f-9fca9df9eb47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#setup\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!rm -rf dataset\n",
        "!unzip {base}dataset.zip>/dev/null\n",
        "#pip install tensorflow scikit-learn imbalanced-learn pandas opencv-python-headless\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CATuG8sOViYQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random as rn\n",
        "import tensorflow as tf\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "np.random.seed(0)\n",
        "rn.seed(0)\n",
        "tf.random.set_seed(0)\n",
        "from datetime import datetime\n",
        "from glob import glob\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.combine import SMOTEENN\n",
        "from random import randint\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.applications import MobileNetV3Small, MobileNetV3Large, ResNet50V2\n",
        "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger\n",
        "from tensorflow.keras.layers import Dense, add, Dropout, Flatten, Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, BatchNormalization, Activation, Input, Concatenate, Cropping2D, ActivityRegularization, RandomBrightness, RandomContrast, RandomCrop, RandomFlip, RandomHeight, RandomRotation, RandomTranslation, RandomWidth, RandomZoom\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import codecs\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import time\n",
        "from google.colab import runtime\n",
        "tf.get_logger().setLevel('ERROR')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Ny6SVPtmYFHl"
      },
      "outputs": [],
      "source": [
        "# Util functions\n",
        "def log(message):\n",
        "\tprint(message)\n",
        "\tfile = codecs.open(base+\"log.txt\", \"a\", \"cp1252\", \"replace\")\n",
        "\tprint(message, file=file)\n",
        "\n",
        "def load(file):\n",
        "\tim = cv2.imread(file)\n",
        "\tif im is None:\n",
        "\t\tprint(\"Can't load\", file)\n",
        "\t\treturn\n",
        "\treturn tf.image.resize(im, size[:2])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RQz5sA2kYktu"
      },
      "outputs": [],
      "source": [
        "class DataGenerator(Sequence):\n",
        "\tdef __init__(self,x, y=None, batch_size = 1, mode=\"train\", alpha=0.2):\n",
        "\t\tself.x = x\n",
        "\t\tself.y = y\n",
        "\t\tself.mode = mode\n",
        "\t\tself.alpha = alpha\n",
        "\t\tself.batch_size = batch_size\n",
        "\t\tself.img_gen = ImageDataGenerator(zca_whitening=False, rotation_range=20, shear_range=0.2, width_shift_range=0.2, height_shift_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "\t\tself.on_epoch_end()\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn int(np.ceil(len(self.x) / float(self.batch_size)))\n",
        "\n",
        "\tdef on_epoch_end(self):\n",
        "\t\tself.indexes = np.arange(len(self.x))\n",
        "\t\tif self.mode == \"train\": np.random.shuffle(self.indexes)\n",
        "\n",
        "\tdef aug(self, x):\n",
        "\t\tif self.mode == \"train\" and randint(1,10)>1: x = self.img_gen.random_transform(x)\n",
        "\t\treturn x\n",
        "\n",
        "\tdef __getitem__(self, index):\n",
        "\t\tindexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\t\tx_batch = [imgs[x] for x in self.x[indexes]]\n",
        "\t\tx_batch = np.array(x_batch)\n",
        "\t\t#x_batch = self.x[indexes]\n",
        "\t\tif self.y is not None: y_batch = self.y[indexes]\n",
        "\t\t#if self.mode == \"train\": x_batch, y_batch = self.mixup(x_batch, y_batch)\n",
        "\t\tif self.y is None: return x_batch\n",
        "\t\treturn x_batch, y_batch\n",
        "\n",
        "\tdef mixup(self, x, y):\n",
        "\t\tn = x.shape[0]\n",
        "\t\tl = np.random.beta(self.alpha, self.alpha, n)\n",
        "\t\tx_l = l.reshape(n, 1, 1, 1)\n",
        "\t\ty_l = l.reshape(n, 1)\n",
        "\t\t#index_l = np.arange(n)\n",
        "\t\t#np.random.shuffle(index_l)\n",
        "\n",
        "\t\tx1 = x\n",
        "\t\tx2 = x[::-1]\n",
        "\t\tx = x1 * x_l + x2 * (1 - x_l)\n",
        "\t\t\n",
        "\t\ty1 = y\n",
        "\t\ty2 = y[::-1]\n",
        "\t\ty = y1 * y_l + y2 * (1 - y_l)\n",
        "\t\treturn x, y\n",
        "\n",
        "\tdef mixup2(self, x, y):\n",
        "\t\tn = x.shape[0]\n",
        "\t\tl = np.random.beta(self.alpha, self.alpha)\n",
        "\t\t\n",
        "\t\txl = x[::-1]\n",
        "\t\tx = x * l + xl * (1 - l)\n",
        "\t\t\n",
        "\t\tyl = y[::-1]\n",
        "\t\ty = y * l + yl * (1 - l)\n",
        "\t\treturn x, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mxjjkWeKYqsQ"
      },
      "outputs": [],
      "source": [
        "class MetricCallback(Callback):\n",
        "\tdef __init__(self, x, y, k=0, patience=0, restore_best=True):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.x = x\n",
        "\t\tself.y = y\n",
        "\t\tself.k=k\n",
        "\t\tself.best_score = 0.0\n",
        "\t\tself.best_epoch = 0\n",
        "\t\tself.best_weights = None\n",
        "\t\tself.patience = patience\n",
        "\t\tself.restore_best = restore_best\n",
        "\n",
        "\tdef restore(self):\n",
        "\t\tself.model.set_weights(self.best_weights)\n",
        "\n",
        "\tdef on_epoch_end(self, epoch, logs={}):\n",
        "\t\tpred_gen= DataGenerator(self.x, mode=\"predict\")\n",
        "\t\tpreds = self.model.predict(pred_gen, verbose=0)\n",
        "\t\tfinal = f1_score(self.y.argmax(-1), preds.argmax(-1), average='micro')\n",
        "\t\tif final>self.best_score:\n",
        "\t\t\tfor f in glob(\"*.h5\"): os.remove(f)\n",
        "\t\t\tself.model.save(f\"model {self.k+1} {epoch+1} f{final:.3f}.h5\")\n",
        "\t\t\t!rm {base}*.h5\n",
        "\t\t\t!cp *.h5 {base}\n",
        "\t\t\tlog(f\"{epoch+1} Best Score: improved from {self.best_score:.3f} to {final:.3f}\")\n",
        "\t\t\tself.best_score = final\n",
        "\t\t\tself.best_epoch = epoch\n",
        "\t\t\tself.best_weights = self.model.get_weights()\n",
        "\t\telse: log(f\"{epoch+1} Score: {final:.3f}, Best epoch: {self.best_epoch+1}, {self.best_score:.3f}\")\n",
        "\n",
        "\t\tif self.patience>0 and epoch-self.best_epoch >= self.patience:\n",
        "\t\t\tprint(\"Stopping...\")\n",
        "\t\t\tself.stopped_epoch = epoch\n",
        "\t\t\tself.model.stop_training = True\n",
        "\t\t\tif self.restore_best: self.restore()\n",
        "\t\t\treturn\n",
        "\n",
        "\t\tif not epoch == self.best_epoch and (epoch-self.best_epoch)%int(self.patience/2) == 0:\n",
        "\t\t\told_lr = float(tf.keras.backend.get_value(self.model.optimizer.lr))\n",
        "\t\t\tnew_lr = old_lr * 0.1\n",
        "\t\t\ttf.keras.backend.set_value(self.model.optimizer.lr, new_lr)\n",
        "\t\t\tself.restore()\n",
        "\t\t\tlog(f\"Reducing learning rate from {old_lr} to {new_lr}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "U7Qz6pFhZDGo"
      },
      "outputs": [],
      "source": [
        "# Model\n",
        "def describe(model):\n",
        "\tfor i, layer in enumerate(model.layers):\n",
        "\t\tif layer.trainable: print(i, layer.name, layer.trainable, layer.input_shape, layer.output_shape)\n",
        "\t\tif hasattr(layer, \"layers\"): describe(layer)\n",
        "\n",
        "def create_model(input_shape, output_shape):\n",
        "\tdata_augmentation = Sequential([\n",
        "\t\tRandomBrightness(0.2),\n",
        "\t\tRandomContrast(0.2),\n",
        "\t\tRandomFlip(),\n",
        "\t\tRandomRotation(0.2),\n",
        "\t\tRandomTranslation(0.2, 0.2),\n",
        "\t\tRandomZoom(0.2, 0.2)\n",
        "\t])\n",
        "\tbase_model = MobileNetV3Small(include_top=False, input_shape=input_shape, weights='imagenet', pooling=\"avg\")\n",
        "\tbase_model.trainable = False\n",
        "\tinputs = Input(shape=input_shape)\n",
        "\tx = data_augmentation(inputs)\n",
        "\tx = base_model(x, training=False)\n",
        "\tx = Dense(256)(x)\n",
        "\tx = BatchNormalization()(x)\n",
        "\tx = Activation(\"relu\")(x)\n",
        "\tx = Dropout(0.2)(x)\n",
        "\toutputs =Dense(output_shape,activation='softmax')(x)\n",
        "\tmodel=Model(inputs=inputs, outputs=outputs)\n",
        "\tmodel.compile(optimizer=Adam(1e-3), loss='CategoricalCrossentropy',metrics=['accuracy'])\n",
        "\tdescribe(model)\n",
        "\tprint(model.summary())\n",
        "\treturn model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vaQJs_5pG-Fi"
      },
      "outputs": [],
      "source": [
        "#Imblearn\n",
        "def balance(x, y):\n",
        "\tprint(\"Balancing samples...\")\n",
        "\tros = RandomOverSampler()\n",
        "\tx, y = ros.fit_resample(x.reshape(-1,1), y)\n",
        "\t# Can't use synthetic for memory limitation\n",
        "\t#smote_enn = SMOTEENN(random_state=0)\n",
        "\t#x, y = smote_enn.fit_resample(x, y)\n",
        "\tx = x.reshape(-1)\n",
        "\tu, c = np.unique(y, return_counts=True)\n",
        "\tnames = [le.classes_[l] for l in u]\n",
        "\tdist = list(zip(names, c))\n",
        "\tdist = sorted(dist, key = lambda x: x[1])\n",
        "\tprint(\"Distribution after over sampling:\", dist)\n",
        "\treturn x, y\n",
        "\t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8d8jD0GPspR",
        "outputId": "6b6f1e4e-cb9c-49d7-c924-5e5607a7f155"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting at: 12/05/2022, 13:27:49\n",
            "Size: (224, 224, 3), batch_size: 32, k_fold: 0\n",
            "Tensorflow: 2.9.2\n",
            "SKLearn: 1.0.2\n"
          ]
        }
      ],
      "source": [
        "size = (224, 224, 3)\n",
        "batch_size = 32\n",
        "k=0\n",
        "t_start = time.time()\n",
        "now = datetime.now()\n",
        "date_time = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
        "log(f\"Starting at: {date_time}\")\n",
        "log(f\"Size: {size}, batch_size: {batch_size}, k_fold: {k}\")\n",
        "log(f\"Tensorflow: {tf.version.VERSION}\")\n",
        "log(f\"SKLearn: {sklearn.__version__}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ex6JzOpffOH",
        "outputId": "231f4b96-e47e-4c2e-fd9b-7fdc4220bc15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "knob                 679\n",
            "non-interactive      389\n",
            "remove               293\n",
            "needle               173\n",
            "icon                  64\n",
            "button                53\n",
            "radio button          35\n",
            "multiple knobs        31\n",
            "dropdown              29\n",
            "multiple elements     25\n",
            "meter                 24\n",
            "slider                20\n",
            "light                 16\n",
            "arrow                 15\n",
            "switch                12\n",
            "unknown               10\n",
            "other                  8\n",
            "multiple buttons       8\n",
            "music note             7\n",
            "multiple switches      4\n",
            "confused               2\n",
            "graph                  1\n",
            "fader                  1\n",
            "wheel                  1\n",
            "scale                  1\n",
            "Name: label, dtype: int64\n",
            "Removing ['unknown', 'other', 'multiple buttons', 'music note', 'multiple switches', 'confused', 'graph', 'fader', 'wheel', 'scale']\n",
            "knob                 679\n",
            "non-interactive      389\n",
            "remove               293\n",
            "needle               173\n",
            "icon                  64\n",
            "button                53\n",
            "radio button          35\n",
            "multiple knobs        31\n",
            "dropdown              29\n",
            "multiple elements     25\n",
            "meter                 24\n",
            "slider                20\n",
            "light                 16\n",
            "arrow                 15\n",
            "switch                12\n",
            "Name: label, dtype: int64\n",
            "Can't load dataset/streep6.gif\n"
          ]
        }
      ],
      "source": [
        "#Load and cleanup\n",
        "df = pd. read_csv (base+\"label.csv\")\n",
        "print(df['label'].value_counts())\n",
        "search = df['label'].value_counts().reset_index(name=\"count\").query(\"count < 11\")[\"index\"]\n",
        "print(\"Removing\", search.tolist())\n",
        "df = df[~df['label'].isin(search)]\n",
        "df = df.dropna(subset=['label'])\n",
        "print(df['label'].value_counts())\n",
        "\n",
        "files = df['image']\n",
        "files = [\"dataset/\"+file for file in files]\n",
        "labels = df['label']\n",
        "bad = []\n",
        "imgs = {}\n",
        "for i in range(len(files)):\n",
        "\tdata = load(files[i])\n",
        "\tif data is None: bad.append(i)\n",
        "\telse: imgs[files[i]] = data\n",
        "x = np.delete(np.array(files), np.array(bad))\n",
        "y = np.delete(np.array(labels), np.array(bad))\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fINs8M_Bey8L",
        "outputId": "f47dc44c-82fd-4424-8bd5-03fdbe67419a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train: (1485,), y_train:(1485,), x_test: (372,), y_test: (372,)\n",
            "x_train: (1485,), y_train:(1485, 15), x_test: (372,), y_test: (372, 15)\n"
          ]
        }
      ],
      "source": [
        "#Divide train and test set\n",
        "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.2)\n",
        "splits = list(sss.split(np.zeros(y.shape[0]), y))\n",
        "train_index, test_index = splits[k]\n",
        "x_train, y_train = x[train_index], y[train_index]\n",
        "x_test, y_test = x[test_index], y[test_index]\n",
        "log(f\"x_train: {x_train.shape}, y_train:{y_train.shape}, x_test: {x_test.shape}, y_test: {y_test.shape}\")\n",
        "#x_train, y_train = balance(x_train, y_train)\n",
        "y_train= to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "log(f\"x_train: {x_train.shape}, y_train:{y_train.shape}, x_test: {x_test.shape}, y_test: {y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvfFhU5Ie8cB",
        "outputId": "5388c9c4-352d-49fc-a0c2-1efe8205d227"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training fold 0...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_small_224_1.0_float_no_top_v2.h5\n",
            "4334752/4334752 [==============================] - 0s 0us/step\n",
            "0 input_2 True [(None, 224, 224, 3)] [(None, 224, 224, 3)]\n",
            "1 sequential True (None, 224, 224, 3) (None, 224, 224, 3)\n",
            "0 random_brightness True (None, 224, 224, 3) (None, 224, 224, 3)\n",
            "1 random_contrast True (None, 224, 224, 3) (None, 224, 224, 3)\n",
            "2 random_flip True (None, 224, 224, 3) (None, 224, 224, 3)\n",
            "3 random_rotation True (None, 224, 224, 3) (None, 224, 224, 3)\n",
            "4 random_translation True (None, 224, 224, 3) (None, 224, 224, 3)\n",
            "5 random_zoom True (None, 224, 224, 3) (None, 224, 224, 3)\n",
            "3 dense True (None, 576) (None, 256)\n",
            "4 batch_normalization True (None, 256) (None, 256)\n",
            "5 activation True (None, 256) (None, 256)\n",
            "6 dropout True (None, 256) (None, 256)\n",
            "7 dense_1 True (None, 256) (None, 15)\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " sequential (Sequential)     (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " MobilenetV3small (Functiona  (None, 576)              939120    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               147712    \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 256)              1024      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 256)               0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 15)                3855      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,091,711\n",
            "Trainable params: 152,079\n",
            "Non-trainable params: 939,632\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/1000\n",
            "1 Best Score: improved from 0.000 to 0.583\n",
            "47/47 - 35s - loss: 2.4661 - accuracy: 0.3960 - val_loss: 1.3708 - val_accuracy: 0.5833 - 35s/epoch - 743ms/step\n",
            "Epoch 2/1000\n",
            "2 Best Score: improved from 0.583 to 0.591\n",
            "47/47 - 17s - loss: 1.4410 - accuracy: 0.5428 - val_loss: 1.2684 - val_accuracy: 0.5914 - 17s/epoch - 364ms/step\n",
            "Epoch 3/1000\n",
            "3 Best Score: improved from 0.591 to 0.621\n",
            "47/47 - 17s - loss: 1.2617 - accuracy: 0.5643 - val_loss: 1.1538 - val_accuracy: 0.6210 - 17s/epoch - 366ms/step\n",
            "Epoch 4/1000\n",
            "4 Best Score: improved from 0.621 to 0.624\n",
            "47/47 - 19s - loss: 1.1528 - accuracy: 0.6114 - val_loss: 1.1319 - val_accuracy: 0.6237 - 19s/epoch - 398ms/step\n",
            "Epoch 5/1000\n",
            "5 Score: 0.618, Best epoch: 4, 0.624\n",
            "47/47 - 17s - loss: 0.9968 - accuracy: 0.6606 - val_loss: 1.0345 - val_accuracy: 0.6183 - 17s/epoch - 353ms/step\n",
            "Epoch 6/1000\n",
            "6 Best Score: improved from 0.624 to 0.634\n",
            "47/47 - 17s - loss: 0.8820 - accuracy: 0.6545 - val_loss: 1.0462 - val_accuracy: 0.6344 - 17s/epoch - 365ms/step\n",
            "Epoch 7/1000\n",
            "7 Score: 0.618, Best epoch: 6, 0.634\n",
            "47/47 - 17s - loss: 0.8541 - accuracy: 0.6801 - val_loss: 1.0759 - val_accuracy: 0.6183 - 17s/epoch - 352ms/step\n",
            "Epoch 8/1000\n",
            "8 Best Score: improved from 0.634 to 0.667\n",
            "47/47 - 17s - loss: 0.8144 - accuracy: 0.6741 - val_loss: 1.0620 - val_accuracy: 0.6667 - 17s/epoch - 370ms/step\n",
            "Epoch 9/1000\n",
            "9 Best Score: improved from 0.667 to 0.680\n",
            "47/47 - 17s - loss: 0.7486 - accuracy: 0.6815 - val_loss: 0.9884 - val_accuracy: 0.6801 - 17s/epoch - 359ms/step\n",
            "Epoch 10/1000\n",
            "10 Score: 0.634, Best epoch: 9, 0.680\n",
            "47/47 - 17s - loss: 0.6927 - accuracy: 0.7219 - val_loss: 1.0704 - val_accuracy: 0.6344 - 17s/epoch - 359ms/step\n",
            "Epoch 11/1000\n",
            "11 Score: 0.632, Best epoch: 9, 0.680\n",
            "47/47 - 17s - loss: 0.6629 - accuracy: 0.6909 - val_loss: 1.0509 - val_accuracy: 0.6317 - 17s/epoch - 354ms/step\n",
            "Epoch 12/1000\n",
            "12 Score: 0.672, Best epoch: 9, 0.680\n",
            "47/47 - 17s - loss: 0.5930 - accuracy: 0.7165 - val_loss: 1.0014 - val_accuracy: 0.6720 - 17s/epoch - 353ms/step\n",
            "Epoch 13/1000\n",
            "13 Score: 0.672, Best epoch: 9, 0.680\n",
            "47/47 - 16s - loss: 0.6293 - accuracy: 0.7030 - val_loss: 0.9695 - val_accuracy: 0.6720 - 16s/epoch - 350ms/step\n",
            "Epoch 14/1000\n",
            "14 Best Score: improved from 0.680 to 0.694\n",
            "47/47 - 17s - loss: 0.5938 - accuracy: 0.7246 - val_loss: 0.8807 - val_accuracy: 0.6935 - 17s/epoch - 361ms/step\n",
            "Epoch 15/1000\n",
            "15 Best Score: improved from 0.694 to 0.712\n",
            "47/47 - 17s - loss: 0.5636 - accuracy: 0.7266 - val_loss: 0.9023 - val_accuracy: 0.7124 - 17s/epoch - 361ms/step\n",
            "Epoch 16/1000\n",
            "16 Score: 0.661, Best epoch: 15, 0.712\n",
            "47/47 - 16s - loss: 0.5444 - accuracy: 0.7367 - val_loss: 1.0242 - val_accuracy: 0.6613 - 16s/epoch - 349ms/step\n",
            "Epoch 17/1000\n",
            "17 Score: 0.699, Best epoch: 15, 0.712\n",
            "47/47 - 18s - loss: 0.5400 - accuracy: 0.7333 - val_loss: 0.9191 - val_accuracy: 0.6989 - 18s/epoch - 381ms/step\n",
            "Epoch 18/1000\n",
            "18 Best Score: improved from 0.712 to 0.720\n",
            "47/47 - 17s - loss: 0.5295 - accuracy: 0.7549 - val_loss: 0.9593 - val_accuracy: 0.7204 - 17s/epoch - 360ms/step\n",
            "Epoch 19/1000\n",
            "19 Score: 0.634, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.5457 - accuracy: 0.7461 - val_loss: 1.1057 - val_accuracy: 0.6344 - 16s/epoch - 349ms/step\n",
            "Epoch 20/1000\n",
            "20 Score: 0.675, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.5249 - accuracy: 0.7327 - val_loss: 0.9487 - val_accuracy: 0.6747 - 16s/epoch - 350ms/step\n",
            "Epoch 21/1000\n",
            "21 Score: 0.664, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.4675 - accuracy: 0.7448 - val_loss: 0.9528 - val_accuracy: 0.6640 - 16s/epoch - 344ms/step\n",
            "Epoch 22/1000\n",
            "22 Score: 0.675, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.4998 - accuracy: 0.7502 - val_loss: 0.9058 - val_accuracy: 0.6747 - 16s/epoch - 347ms/step\n",
            "Epoch 23/1000\n",
            "23 Score: 0.659, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.4856 - accuracy: 0.7616 - val_loss: 0.9876 - val_accuracy: 0.6586 - 16s/epoch - 343ms/step\n",
            "Epoch 24/1000\n",
            "24 Score: 0.672, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.4495 - accuracy: 0.7609 - val_loss: 0.9753 - val_accuracy: 0.6720 - 16s/epoch - 349ms/step\n",
            "Epoch 25/1000\n",
            "25 Score: 0.683, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.4271 - accuracy: 0.7805 - val_loss: 0.9625 - val_accuracy: 0.6828 - 16s/epoch - 351ms/step\n",
            "Epoch 26/1000\n",
            "26 Score: 0.656, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.4646 - accuracy: 0.7630 - val_loss: 1.0036 - val_accuracy: 0.6559 - 16s/epoch - 345ms/step\n",
            "Epoch 27/1000\n",
            "27 Score: 0.688, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.4004 - accuracy: 0.7616 - val_loss: 0.9337 - val_accuracy: 0.6882 - 16s/epoch - 347ms/step\n",
            "Epoch 28/1000\n",
            "28 Score: 0.702, Best epoch: 18, 0.720\n",
            "47/47 - 17s - loss: 0.4034 - accuracy: 0.7771 - val_loss: 0.8793 - val_accuracy: 0.7016 - 17s/epoch - 357ms/step\n",
            "Epoch 29/1000\n",
            "29 Score: 0.683, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.4314 - accuracy: 0.7764 - val_loss: 0.9373 - val_accuracy: 0.6828 - 16s/epoch - 347ms/step\n",
            "Epoch 30/1000\n",
            "30 Score: 0.685, Best epoch: 18, 0.720\n",
            "47/47 - 17s - loss: 0.3777 - accuracy: 0.7764 - val_loss: 0.9207 - val_accuracy: 0.6855 - 17s/epoch - 366ms/step\n",
            "Epoch 31/1000\n",
            "31 Score: 0.659, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.4750 - accuracy: 0.7825 - val_loss: 0.9565 - val_accuracy: 0.6586 - 16s/epoch - 347ms/step\n",
            "Epoch 32/1000\n",
            "32 Score: 0.688, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.3942 - accuracy: 0.7582 - val_loss: 0.9599 - val_accuracy: 0.6882 - 16s/epoch - 350ms/step\n",
            "Epoch 33/1000\n",
            "33 Score: 0.640, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.4307 - accuracy: 0.7805 - val_loss: 1.0763 - val_accuracy: 0.6398 - 16s/epoch - 344ms/step\n",
            "Epoch 34/1000\n",
            "34 Score: 0.694, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.4084 - accuracy: 0.7731 - val_loss: 0.9743 - val_accuracy: 0.6935 - 16s/epoch - 342ms/step\n",
            "Epoch 35/1000\n",
            "35 Score: 0.683, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.3745 - accuracy: 0.7933 - val_loss: 0.9858 - val_accuracy: 0.6828 - 16s/epoch - 344ms/step\n",
            "Epoch 36/1000\n",
            "36 Score: 0.694, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.4043 - accuracy: 0.7791 - val_loss: 0.9702 - val_accuracy: 0.6935 - 16s/epoch - 345ms/step\n",
            "Epoch 37/1000\n",
            "37 Score: 0.677, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.3835 - accuracy: 0.8088 - val_loss: 0.9555 - val_accuracy: 0.6774 - 16s/epoch - 340ms/step\n",
            "Epoch 38/1000\n",
            "38 Score: 0.694, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.3969 - accuracy: 0.7973 - val_loss: 0.9204 - val_accuracy: 0.6935 - 16s/epoch - 340ms/step\n",
            "Epoch 39/1000\n",
            "39 Score: 0.656, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.3837 - accuracy: 0.7886 - val_loss: 1.0022 - val_accuracy: 0.6559 - 16s/epoch - 340ms/step\n",
            "Epoch 40/1000\n",
            "40 Score: 0.691, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.3736 - accuracy: 0.7906 - val_loss: 0.9523 - val_accuracy: 0.6909 - 16s/epoch - 341ms/step\n",
            "Epoch 41/1000\n",
            "41 Score: 0.667, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.4214 - accuracy: 0.7939 - val_loss: 1.0639 - val_accuracy: 0.6667 - 16s/epoch - 342ms/step\n",
            "Epoch 42/1000\n",
            "42 Score: 0.659, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.3928 - accuracy: 0.8054 - val_loss: 1.0058 - val_accuracy: 0.6586 - 16s/epoch - 339ms/step\n",
            "Epoch 43/1000\n",
            "43 Score: 0.696, Best epoch: 18, 0.720\n",
            "Reducing learning rate from 0.0010000000474974513 to 0.00010000000474974513\n",
            "47/47 - 16s - loss: 0.4084 - accuracy: 0.7993 - val_loss: 0.9486 - val_accuracy: 0.6962 - 16s/epoch - 340ms/step\n",
            "Epoch 44/1000\n",
            "44 Score: 0.688, Best epoch: 18, 0.720\n",
            "47/47 - 17s - loss: 0.5392 - accuracy: 0.7596 - val_loss: 0.9594 - val_accuracy: 0.6882 - 17s/epoch - 372ms/step\n",
            "Epoch 45/1000\n",
            "45 Score: 0.699, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.4676 - accuracy: 0.7616 - val_loss: 0.9567 - val_accuracy: 0.6989 - 16s/epoch - 337ms/step\n",
            "Epoch 46/1000\n",
            "46 Score: 0.694, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.4966 - accuracy: 0.7549 - val_loss: 0.9534 - val_accuracy: 0.6935 - 16s/epoch - 338ms/step\n",
            "Epoch 47/1000\n",
            "47 Score: 0.707, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.4485 - accuracy: 0.7657 - val_loss: 0.9491 - val_accuracy: 0.7070 - 16s/epoch - 339ms/step\n",
            "Epoch 48/1000\n",
            "48 Score: 0.704, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.4346 - accuracy: 0.7731 - val_loss: 0.9445 - val_accuracy: 0.7043 - 16s/epoch - 341ms/step\n",
            "Epoch 49/1000\n",
            "49 Score: 0.707, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.4521 - accuracy: 0.7859 - val_loss: 0.9325 - val_accuracy: 0.7070 - 16s/epoch - 340ms/step\n",
            "Epoch 50/1000\n",
            "50 Score: 0.715, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.4261 - accuracy: 0.7657 - val_loss: 0.9300 - val_accuracy: 0.7151 - 16s/epoch - 343ms/step\n",
            "Epoch 51/1000\n",
            "51 Score: 0.710, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.4290 - accuracy: 0.7785 - val_loss: 0.9342 - val_accuracy: 0.7097 - 16s/epoch - 340ms/step\n",
            "Epoch 52/1000\n",
            "52 Score: 0.712, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.4547 - accuracy: 0.7886 - val_loss: 0.9350 - val_accuracy: 0.7124 - 16s/epoch - 343ms/step\n",
            "Epoch 53/1000\n",
            "53 Score: 0.696, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.4714 - accuracy: 0.7717 - val_loss: 0.9351 - val_accuracy: 0.6962 - 16s/epoch - 342ms/step\n",
            "Epoch 54/1000\n",
            "54 Score: 0.694, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.4532 - accuracy: 0.7697 - val_loss: 0.9324 - val_accuracy: 0.6935 - 16s/epoch - 339ms/step\n",
            "Epoch 55/1000\n",
            "55 Score: 0.694, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.4627 - accuracy: 0.7589 - val_loss: 0.9310 - val_accuracy: 0.6935 - 16s/epoch - 340ms/step\n",
            "Epoch 56/1000\n",
            "56 Score: 0.691, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.4362 - accuracy: 0.7690 - val_loss: 0.9289 - val_accuracy: 0.6909 - 16s/epoch - 342ms/step\n",
            "Epoch 57/1000\n",
            "57 Score: 0.691, Best epoch: 18, 0.720\n",
            "47/47 - 18s - loss: 0.4058 - accuracy: 0.7798 - val_loss: 0.9290 - val_accuracy: 0.6909 - 18s/epoch - 374ms/step\n",
            "Epoch 58/1000\n",
            "58 Score: 0.704, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.4173 - accuracy: 0.7744 - val_loss: 0.9262 - val_accuracy: 0.7043 - 16s/epoch - 346ms/step\n",
            "Epoch 59/1000\n",
            "59 Score: 0.707, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.4261 - accuracy: 0.7690 - val_loss: 0.9186 - val_accuracy: 0.7070 - 16s/epoch - 341ms/step\n",
            "Epoch 60/1000\n",
            "60 Score: 0.702, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.4278 - accuracy: 0.7933 - val_loss: 0.9187 - val_accuracy: 0.7016 - 16s/epoch - 342ms/step\n",
            "Epoch 61/1000\n",
            "61 Score: 0.710, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.4030 - accuracy: 0.7832 - val_loss: 0.9218 - val_accuracy: 0.7097 - 16s/epoch - 343ms/step\n",
            "Epoch 62/1000\n",
            "62 Score: 0.712, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.3899 - accuracy: 0.7859 - val_loss: 0.9184 - val_accuracy: 0.7124 - 16s/epoch - 341ms/step\n",
            "Epoch 63/1000\n",
            "63 Score: 0.720, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.4436 - accuracy: 0.7818 - val_loss: 0.9058 - val_accuracy: 0.7204 - 16s/epoch - 341ms/step\n",
            "Epoch 64/1000\n",
            "64 Score: 0.712, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.4228 - accuracy: 0.7865 - val_loss: 0.9086 - val_accuracy: 0.7124 - 16s/epoch - 342ms/step\n",
            "Epoch 65/1000\n",
            "65 Score: 0.707, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.4202 - accuracy: 0.7717 - val_loss: 0.9156 - val_accuracy: 0.7070 - 16s/epoch - 343ms/step\n",
            "Epoch 66/1000\n",
            "66 Score: 0.704, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.4061 - accuracy: 0.7771 - val_loss: 0.9235 - val_accuracy: 0.7043 - 16s/epoch - 340ms/step\n",
            "Epoch 67/1000\n",
            "67 Score: 0.710, Best epoch: 18, 0.720\n",
            "47/47 - 16s - loss: 0.3804 - accuracy: 0.7845 - val_loss: 0.9201 - val_accuracy: 0.7097 - 16s/epoch - 342ms/step\n",
            "Epoch 68/1000\n",
            "68 Score: 0.718, Best epoch: 18, 0.720\n",
            "Stopping...\n",
            "47/47 - 16s - loss: 0.3891 - accuracy: 0.7926 - val_loss: 0.9177 - val_accuracy: 0.7177 - 16s/epoch - 342ms/step\n"
          ]
        }
      ],
      "source": [
        "#Train\n",
        "log(f\"Training fold {k}...\")\n",
        "model = create_model(size, y_train.shape[1])\n",
        "train_gen= DataGenerator(x_train, y_train, batch_size=batch_size)\n",
        "val_gen= DataGenerator(x_test, y_test, batch_size=batch_size, mode=\"val\")\n",
        "mc = MetricCallback(x_test, y_test, patience=50)\n",
        "logger = CSVLogger(base+'train.csv')\n",
        "callbacks = [mc, logger]\n",
        "weight = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
        "weight = dict(zip(np.unique(y), weight))\n",
        "history = model.fit(train_gen, validation_data=val_gen, epochs=1000, callbacks =callbacks, verbose=2, class_weight=weight) #, workers=multiprocessing.cpu_count(), use_multiprocessing=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qrYuVHAzfBSe",
        "outputId": "8137053f-42a7-4655-cc26-1058f5e4cb8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "372/372 [==============================] - 3s 7ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-56bce2af8508>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpred_gen\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"predict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersect1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one label specified must be in y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mintersect1d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36mintersect1d\u001b[0;34m(ar1, ar2, assume_unique, return_indices)\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maux\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maux_sort_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maux\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0maux\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'"
          ]
        }
      ],
      "source": [
        "#Predict\n",
        "pred_gen= DataGenerator(x_test, mode=\"predict\")\n",
        "preds = model.predict(pred_gen)\n",
        "matrix = confusion_matrix(y_test.argmax(-1), preds.argmax(-1))\n",
        "for i,m in enumerate(matrix):\n",
        "  row = [(le.classes_[j], k) for j, k in enumerate(m) if k>0]\n",
        "  print(i, le.classes_[i], row)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#End\n",
        "now = datetime.now()\n",
        "date_time = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
        "log(f\"Ending at: {date_time}\")\n",
        "t_finish = time.time()\n",
        "total_time = (t_finish-t_start)/60\n",
        "log(f\"It took {total_time} minutes\")\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "0qnKz5UYol16",
        "outputId": "86036a55-f4a3-47ec-a493-8b34fd8387dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 arrow [('arrow', 2), ('light', 1)]\n",
            "1 button [('button', 6), ('light', 4), ('remove', 1)]\n",
            "2 dropdown [('dropdown', 3), ('icon', 1), ('non-interactive', 1), ('remove', 1)]\n",
            "3 icon [('arrow', 2), ('icon', 8), ('knob', 1), ('radio button', 1), ('remove', 1)]\n",
            "4 knob [('knob', 135), ('remove', 1)]\n",
            "5 light [('button', 1), ('knob', 1), ('light', 1)]\n",
            "6 meter [('arrow', 1), ('meter', 3), ('remove', 1)]\n",
            "7 multiple elements [('multiple elements', 3), ('non-interactive', 1), ('radio button', 1)]\n",
            "8 multiple knobs [('knob', 1), ('multiple knobs', 4), ('remove', 1)]\n",
            "9 needle [('needle', 29), ('remove', 6)]\n",
            "10 non-interactive [('arrow', 2), ('button', 2), ('dropdown', 3), ('icon', 4), ('knob', 1), ('meter', 7), ('multiple elements', 1), ('needle', 2), ('non-interactive', 38), ('radio button', 1), ('remove', 16), ('slider', 1)]\n",
            "11 radio button [('arrow', 1), ('dropdown', 1), ('needle', 1), ('radio button', 4)]\n",
            "12 remove [('arrow', 4), ('icon', 6), ('knob', 1), ('light', 1), ('meter', 4), ('needle', 3), ('non-interactive', 6), ('remove', 31), ('slider', 2)]\n",
            "13 slider [('arrow', 1), ('icon', 2), ('meter', 1)]\n",
            "14 switch [('radio button', 1), ('switch', 1)]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNmq06hJZCQDqAv3drsEyH"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}