{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Pa9oTbZXovX",
        "outputId": "cca39ed2-6847-49fd-b6ef-09710ae6ef22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Dec  5 16:37:33 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P0    32W /  70W |   2872MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "Not using a high-RAM runtime\n"
          ]
        }
      ],
      "source": [
        "    base = 'gdrive/MyDrive/ppat/chi_train/'\n",
        "\n",
        "#Runtime Info\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrnKX9eIGzK2",
        "outputId": "825cc044-8d98-482b-bd97-068600de7c1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#setup\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!rm -rf dataset\n",
        "!unzip {base}dataset.zip>/dev/null\n",
        "#pip install tensorflow scikit-learn imbalanced-learn pandas opencv-python-headless\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "CATuG8sOViYQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random as rn\n",
        "import tensorflow as tf\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "np.random.seed(0)\n",
        "rn.seed(0)\n",
        "tf.random.set_seed(0)\n",
        "from datetime import datetime\n",
        "from glob import glob\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.combine import SMOTEENN\n",
        "from random import randint\n",
        "import sklearn\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import f1_score, confusion_matrix, precision_recall_fscore_support\n",
        "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.applications import MobileNetV3Small, MobileNetV3Large, ResNet50V2\n",
        "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger\n",
        "from tensorflow.keras.layers import Dense, add, Dropout, Flatten, Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, BatchNormalization, Activation, Input, Concatenate, Cropping2D, ActivityRegularization, RandomBrightness, RandomContrast, RandomCrop, RandomFlip, RandomHeight, RandomRotation, RandomTranslation, RandomWidth, RandomZoom\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import codecs\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import time\n",
        "from google.colab import runtime\n",
        "tf.get_logger().setLevel('ERROR')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Ny6SVPtmYFHl"
      },
      "outputs": [],
      "source": [
        "# Util functions\n",
        "def log(message):\n",
        "\tprint(message)\n",
        "\tfile = codecs.open(base+\"log.txt\", \"a\", \"cp1252\", \"replace\")\n",
        "\tprint(message, file=file)\n",
        "\n",
        "def load(file):\n",
        "\tim = cv2.imread(file)\n",
        "\tif im is None:\n",
        "\t\tprint(\"Can't load\", file)\n",
        "\t\treturn\n",
        "\treturn tf.image.resize(im, size[:2])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "RQz5sA2kYktu"
      },
      "outputs": [],
      "source": [
        "class DataGenerator(Sequence):\n",
        "\tdef __init__(self,x, y=None, batch_size = 1, mode=\"train\", alpha=0.2):\n",
        "\t\tself.x = x\n",
        "\t\tself.y = y\n",
        "\t\tself.mode = mode\n",
        "\t\tself.alpha = alpha\n",
        "\t\tself.batch_size = batch_size\n",
        "\t\tself.img_gen = ImageDataGenerator(zca_whitening=False, rotation_range=20, shear_range=0.2, width_shift_range=0.2, height_shift_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "\t\tself.on_epoch_end()\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn int(np.ceil(len(self.x) / float(self.batch_size)))\n",
        "\n",
        "\tdef on_epoch_end(self):\n",
        "\t\tself.indexes = np.arange(len(self.x))\n",
        "\t\tif self.mode == \"train\": np.random.shuffle(self.indexes)\n",
        "\n",
        "\tdef aug(self, x):\n",
        "\t\tif self.mode == \"train\" and randint(1,10)>1: x = self.img_gen.random_transform(x)\n",
        "\t\treturn x\n",
        "\n",
        "\tdef __getitem__(self, index):\n",
        "\t\tindexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\t\tx_batch = [imgs[x] for x in self.x[indexes]]\n",
        "\t\tx_batch = np.array(x_batch)\n",
        "\t\t#x_batch = self.x[indexes]\n",
        "\t\tif self.y is not None: y_batch = self.y[indexes]\n",
        "\t\t#if self.mode == \"train\": x_batch, y_batch = self.mixup(x_batch, y_batch)\n",
        "\t\tif self.y is None: return x_batch\n",
        "\t\treturn x_batch, y_batch\n",
        "\n",
        "\tdef mixup(self, x, y):\n",
        "\t\tn = x.shape[0]\n",
        "\t\tl = np.random.beta(self.alpha, self.alpha, n)\n",
        "\t\tx_l = l.reshape(n, 1, 1, 1)\n",
        "\t\ty_l = l.reshape(n, 1)\n",
        "\t\t#index_l = np.arange(n)\n",
        "\t\t#np.random.shuffle(index_l)\n",
        "\n",
        "\t\tx1 = x\n",
        "\t\tx2 = x[::-1]\n",
        "\t\tx = x1 * x_l + x2 * (1 - x_l)\n",
        "\t\t\n",
        "\t\ty1 = y\n",
        "\t\ty2 = y[::-1]\n",
        "\t\ty = y1 * y_l + y2 * (1 - y_l)\n",
        "\t\treturn x, y\n",
        "\n",
        "\tdef mixup2(self, x, y):\n",
        "\t\tn = x.shape[0]\n",
        "\t\tl = np.random.beta(self.alpha, self.alpha)\n",
        "\t\t\n",
        "\t\txl = x[::-1]\n",
        "\t\tx = x * l + xl * (1 - l)\n",
        "\t\t\n",
        "\t\tyl = y[::-1]\n",
        "\t\ty = y * l + yl * (1 - l)\n",
        "\t\treturn x, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "mxjjkWeKYqsQ"
      },
      "outputs": [],
      "source": [
        "class MetricCallback(Callback):\n",
        "\tdef __init__(self, x, y, k=0, patience=0, restore_best=True):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.x = x\n",
        "\t\tself.y = y\n",
        "\t\tself.k=k\n",
        "\t\tself.best_score = 0.0\n",
        "\t\tself.best_epoch = 0\n",
        "\t\tself.best_weights = None\n",
        "\t\tself.patience = patience\n",
        "\t\tself.restore_best = restore_best\n",
        "\n",
        "\tdef restore(self):\n",
        "\t\tself.model.set_weights(self.best_weights)\n",
        "\n",
        "\tdef on_epoch_end(self, epoch, logs={}):\n",
        "\t\tpred_gen= DataGenerator(self.x, mode=\"predict\")\n",
        "\t\tpreds = self.model.predict(pred_gen, verbose=0)\n",
        "\t\tfinal = f1_score(self.y.argmax(-1), preds.argmax(-1), average='micro')\n",
        "\t\tif final>self.best_score:\n",
        "\t\t\tfor f in glob(\"*.h5\"): os.remove(f)\n",
        "\t\t\tself.model.save(f\"model {self.k+1} {epoch+1} f{final:.3f}.h5\")\n",
        "\t\t\t!rm {base}*.h5\n",
        "\t\t\t!cp *.h5 {base}\n",
        "\t\t\tlog(f\"{epoch+1} Best Score: improved from {self.best_score:.3f} to {final:.3f}\")\n",
        "\t\t\tself.best_score = final\n",
        "\t\t\tself.best_epoch = epoch\n",
        "\t\t\tself.best_weights = self.model.get_weights()\n",
        "\t\telse: log(f\"{epoch+1} Score: {final:.3f}, Best epoch: {self.best_epoch+1}, {self.best_score:.3f}\")\n",
        "\n",
        "\t\tif self.patience>0 and epoch-self.best_epoch >= self.patience:\n",
        "\t\t\tprint(\"Stopping...\")\n",
        "\t\t\tself.stopped_epoch = epoch\n",
        "\t\t\tself.model.stop_training = True\n",
        "\t\t\tif self.restore_best: self.restore()\n",
        "\t\t\treturn\n",
        "\n",
        "\t\tif not epoch == self.best_epoch and (epoch-self.best_epoch)%int(self.patience/2) == 0:\n",
        "\t\t\told_lr = float(tf.keras.backend.get_value(self.model.optimizer.lr))\n",
        "\t\t\tnew_lr = old_lr * 0.1\n",
        "\t\t\ttf.keras.backend.set_value(self.model.optimizer.lr, new_lr)\n",
        "\t\t\tself.restore()\n",
        "\t\t\tlog(f\"Reducing learning rate from {old_lr} to {new_lr}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "U7Qz6pFhZDGo"
      },
      "outputs": [],
      "source": [
        "# Model\n",
        "def describe(model):\n",
        "\tfor i, layer in enumerate(model.layers):\n",
        "\t\tif layer.trainable: print(i, layer.name, layer.trainable, layer.input_shape, layer.output_shape)\n",
        "\t\tif hasattr(layer, \"layers\"): describe(layer)\n",
        "\n",
        "def create_model(input_shape, output_shape):\n",
        "\tdata_augmentation = Sequential([\n",
        "\t\tRandomBrightness(0.2),\n",
        "\t\tRandomContrast(0.2),\n",
        "\t\tRandomFlip(),\n",
        "\t\tRandomRotation(0.2),\n",
        "\t\tRandomTranslation(0.2, 0.2),\n",
        "\t\tRandomZoom(0.2, 0.2)\n",
        "\t])\n",
        "\tbase_model = MobileNetV3Small(include_top=False, input_shape=input_shape, weights='imagenet', pooling=\"avg\")\n",
        "\tbase_model.trainable = False\n",
        "\tinputs = Input(shape=input_shape)\n",
        "\tx = data_augmentation(inputs)\n",
        "\tx = base_model(x, training=False)\n",
        "\tx = Dense(256)(x)\n",
        "\tx = BatchNormalization()(x)\n",
        "\tx = Activation(\"relu\")(x)\n",
        "\tx = Dropout(0.2)(x)\n",
        "\toutputs =Dense(output_shape,activation='softmax')(x)\n",
        "\tmodel=Model(inputs=inputs, outputs=outputs)\n",
        "\tmodel.compile(optimizer=Adam(1e-3), loss='CategoricalCrossentropy',metrics=['accuracy'])\n",
        "\tdescribe(model)\n",
        "\tprint(model.summary())\n",
        "\treturn model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "vaQJs_5pG-Fi"
      },
      "outputs": [],
      "source": [
        "#Imblearn\n",
        "def balance(x, y):\n",
        "\tprint(\"Balancing samples...\")\n",
        "\tros = RandomOverSampler()\n",
        "\tx, y = ros.fit_resample(x.reshape(-1,1), y)\n",
        "\t# Can't use synthetic for memory limitation\n",
        "\t#smote_enn = SMOTEENN(random_state=0)\n",
        "\t#x, y = smote_enn.fit_resample(x, y)\n",
        "\tx = x.reshape(-1)\n",
        "\tu, c = np.unique(y, return_counts=True)\n",
        "\tnames = [le.classes_[l] for l in u]\n",
        "\tdist = list(zip(names, c))\n",
        "\tdist = sorted(dist, key = lambda x: x[1])\n",
        "\tprint(\"Distribution after over sampling:\", dist)\n",
        "\treturn x, y\n",
        "\t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8d8jD0GPspR",
        "outputId": "c77259e1-0fca-464d-c36a-ecc8590ef4b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting at: 12/05/2022, 16:37:36\n",
            "Size: (224, 224, 3), batch_size: 32, k_fold: 0\n",
            "Tensorflow: 2.9.2\n",
            "SKLearn: 1.0.2\n"
          ]
        }
      ],
      "source": [
        "size = (224, 224, 3)\n",
        "batch_size = 32\n",
        "k=0\n",
        "t_start = time.time()\n",
        "now = datetime.now()\n",
        "date_time = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
        "log(f\"Starting at: {date_time}\")\n",
        "log(f\"Size: {size}, batch_size: {batch_size}, k_fold: {k}\")\n",
        "log(f\"Tensorflow: {tf.version.VERSION}\")\n",
        "log(f\"SKLearn: {sklearn.__version__}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ex6JzOpffOH",
        "outputId": "a6e14ffc-478e-4c5f-f410-3588a2bc8ab4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "knob                 679\n",
            "non-interactive      389\n",
            "remove               293\n",
            "needle               173\n",
            "icon                  64\n",
            "button                53\n",
            "radio button          35\n",
            "multiple knobs        31\n",
            "dropdown              29\n",
            "multiple elements     25\n",
            "meter                 24\n",
            "slider                20\n",
            "light                 16\n",
            "arrow                 15\n",
            "switch                12\n",
            "unknown               10\n",
            "other                  8\n",
            "multiple buttons       8\n",
            "music note             7\n",
            "multiple switches      4\n",
            "confused               2\n",
            "graph                  1\n",
            "fader                  1\n",
            "wheel                  1\n",
            "scale                  1\n",
            "Name: label, dtype: int64\n",
            "Removing ['unknown', 'other', 'multiple buttons', 'music note', 'multiple switches', 'confused', 'graph', 'fader', 'wheel', 'scale']\n",
            "knob                 679\n",
            "non-interactive      389\n",
            "remove               293\n",
            "needle               173\n",
            "icon                  64\n",
            "button                53\n",
            "radio button          35\n",
            "multiple knobs        31\n",
            "dropdown              29\n",
            "multiple elements     25\n",
            "meter                 24\n",
            "slider                20\n",
            "light                 16\n",
            "arrow                 15\n",
            "switch                12\n",
            "Name: label, dtype: int64\n",
            "Can't load dataset/streep6.gif\n"
          ]
        }
      ],
      "source": [
        "#Load and cleanup\n",
        "df = pd. read_csv (base+\"label.csv\")\n",
        "print(df['label'].value_counts())\n",
        "search = df['label'].value_counts().reset_index(name=\"count\").query(\"count < 11\")[\"index\"]\n",
        "print(\"Removing\", search.tolist())\n",
        "df = df[~df['label'].isin(search)]\n",
        "df = df.dropna(subset=['label'])\n",
        "print(df['label'].value_counts())\n",
        "\n",
        "files = df['image']\n",
        "files = [\"dataset/\"+file for file in files]\n",
        "labels = df['label']\n",
        "bad = []\n",
        "imgs = {}\n",
        "for i in range(len(files)):\n",
        "\tdata = load(files[i])\n",
        "\tif data is None: bad.append(i)\n",
        "\telse: imgs[files[i]] = data\n",
        "x = np.delete(np.array(files), np.array(bad))\n",
        "y = np.delete(np.array(labels), np.array(bad))\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fINs8M_Bey8L",
        "outputId": "0390e587-69eb-40cf-f8e2-79b6f1d7fbda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train: (1485,), y_train:(1485,), x_test: (372,), y_test: (372,)\n",
            "x_train: (1485,), y_train:(1485, 15), x_test: (372,), y_test: (372, 15)\n"
          ]
        }
      ],
      "source": [
        "#Divide train and test set\n",
        "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.2)\n",
        "splits = list(sss.split(np.zeros(y.shape[0]), y))\n",
        "train_index, test_index = splits[k]\n",
        "x_train, y_train = x[train_index], y[train_index]\n",
        "x_test, y_test = x[test_index], y[test_index]\n",
        "log(f\"x_train: {x_train.shape}, y_train:{y_train.shape}, x_test: {x_test.shape}, y_test: {y_test.shape}\")\n",
        "#x_train, y_train = balance(x_train, y_train)\n",
        "y_train= to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "log(f\"x_train: {x_train.shape}, y_train:{y_train.shape}, x_test: {x_test.shape}, y_test: {y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvfFhU5Ie8cB",
        "outputId": "ba685e2e-9be3-49ef-c110-89ebb2836de6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training fold 0...\n",
            "0 input_4 True [(None, 224, 224, 3)] [(None, 224, 224, 3)]\n",
            "1 sequential_1 True (None, 224, 224, 3) (None, 224, 224, 3)\n",
            "0 random_brightness_1 True (None, 224, 224, 3) (None, 224, 224, 3)\n",
            "1 random_contrast_1 True (None, 224, 224, 3) (None, 224, 224, 3)\n",
            "2 random_flip_1 True (None, 224, 224, 3) (None, 224, 224, 3)\n",
            "3 random_rotation_1 True (None, 224, 224, 3) (None, 224, 224, 3)\n",
            "4 random_translation_1 True (None, 224, 224, 3) (None, 224, 224, 3)\n",
            "5 random_zoom_1 True (None, 224, 224, 3) (None, 224, 224, 3)\n",
            "3 dense_2 True (None, 576) (None, 256)\n",
            "4 batch_normalization_1 True (None, 256) (None, 256)\n",
            "5 activation_1 True (None, 256) (None, 256)\n",
            "6 dropout_1 True (None, 256) (None, 256)\n",
            "7 dense_3 True (None, 256) (None, 15)\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " sequential_1 (Sequential)   (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " MobilenetV3small (Functiona  (None, 576)              939120    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               147712    \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 15)                3855      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,091,711\n",
            "Trainable params: 152,079\n",
            "Non-trainable params: 939,632\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/1000\n",
            "1 Best Score: improved from 0.000 to 0.583\n",
            "47/47 - 29s - loss: 2.4661 - accuracy: 0.3960 - val_loss: 1.3708 - val_accuracy: 0.5833 - 29s/epoch - 613ms/step\n",
            "Epoch 2/1000\n",
            "2 Best Score: improved from 0.583 to 0.591\n",
            "47/47 - 18s - loss: 1.4410 - accuracy: 0.5428 - val_loss: 1.2684 - val_accuracy: 0.5914 - 18s/epoch - 373ms/step\n",
            "Epoch 3/1000\n",
            "3 Best Score: improved from 0.591 to 0.621\n",
            "47/47 - 18s - loss: 1.2617 - accuracy: 0.5643 - val_loss: 1.1538 - val_accuracy: 0.6210 - 18s/epoch - 375ms/step\n",
            "Epoch 4/1000\n",
            "4 Best Score: improved from 0.621 to 0.624\n",
            "47/47 - 18s - loss: 1.1528 - accuracy: 0.6114 - val_loss: 1.1319 - val_accuracy: 0.6237 - 18s/epoch - 374ms/step\n",
            "Epoch 5/1000\n",
            "5 Score: 0.618, Best epoch: 4, 0.624\n",
            "47/47 - 17s - loss: 0.9968 - accuracy: 0.6606 - val_loss: 1.0345 - val_accuracy: 0.6183 - 17s/epoch - 360ms/step\n",
            "Epoch 6/1000\n",
            "6 Best Score: improved from 0.624 to 0.634\n",
            "47/47 - 18s - loss: 0.8820 - accuracy: 0.6545 - val_loss: 1.0462 - val_accuracy: 0.6344 - 18s/epoch - 376ms/step\n",
            "Epoch 7/1000\n",
            "7 Score: 0.618, Best epoch: 6, 0.634\n",
            "47/47 - 17s - loss: 0.8541 - accuracy: 0.6801 - val_loss: 1.0759 - val_accuracy: 0.6183 - 17s/epoch - 356ms/step\n",
            "Epoch 8/1000\n",
            "8 Best Score: improved from 0.634 to 0.667\n",
            "47/47 - 17s - loss: 0.8144 - accuracy: 0.6741 - val_loss: 1.0620 - val_accuracy: 0.6667 - 17s/epoch - 371ms/step\n",
            "Epoch 9/1000\n",
            "9 Best Score: improved from 0.667 to 0.680\n",
            "47/47 - 18s - loss: 0.7486 - accuracy: 0.6815 - val_loss: 0.9884 - val_accuracy: 0.6801 - 18s/epoch - 374ms/step\n",
            "Epoch 10/1000\n",
            "10 Score: 0.634, Best epoch: 9, 0.680\n",
            "47/47 - 17s - loss: 0.6927 - accuracy: 0.7219 - val_loss: 1.0704 - val_accuracy: 0.6344 - 17s/epoch - 357ms/step\n",
            "Epoch 11/1000\n",
            "11 Score: 0.632, Best epoch: 9, 0.680\n",
            "47/47 - 17s - loss: 0.6629 - accuracy: 0.6909 - val_loss: 1.0509 - val_accuracy: 0.6317 - 17s/epoch - 362ms/step\n",
            "Epoch 12/1000\n",
            "12 Score: 0.672, Best epoch: 9, 0.680\n",
            "47/47 - 17s - loss: 0.5930 - accuracy: 0.7158 - val_loss: 1.0013 - val_accuracy: 0.6720 - 17s/epoch - 359ms/step\n",
            "Epoch 13/1000\n",
            "13 Score: 0.672, Best epoch: 9, 0.680\n",
            "47/47 - 17s - loss: 0.6293 - accuracy: 0.7030 - val_loss: 0.9695 - val_accuracy: 0.6720 - 17s/epoch - 361ms/step\n",
            "Epoch 14/1000\n",
            "14 Best Score: improved from 0.680 to 0.696\n",
            "47/47 - 19s - loss: 0.5937 - accuracy: 0.7246 - val_loss: 0.8803 - val_accuracy: 0.6962 - 19s/epoch - 409ms/step\n",
            "Epoch 15/1000\n",
            "15 Best Score: improved from 0.696 to 0.712\n",
            "47/47 - 18s - loss: 0.5631 - accuracy: 0.7266 - val_loss: 0.9037 - val_accuracy: 0.7124 - 18s/epoch - 378ms/step\n",
            "Epoch 16/1000\n",
            "16 Score: 0.664, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.5447 - accuracy: 0.7347 - val_loss: 1.0257 - val_accuracy: 0.6640 - 17s/epoch - 357ms/step\n",
            "Epoch 17/1000\n",
            "17 Score: 0.696, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.5405 - accuracy: 0.7380 - val_loss: 0.9235 - val_accuracy: 0.6962 - 17s/epoch - 356ms/step\n",
            "Epoch 18/1000\n",
            "18 Score: 0.704, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.5306 - accuracy: 0.7569 - val_loss: 0.9588 - val_accuracy: 0.7043 - 17s/epoch - 357ms/step\n",
            "Epoch 19/1000\n",
            "19 Score: 0.642, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.5470 - accuracy: 0.7475 - val_loss: 1.1042 - val_accuracy: 0.6425 - 17s/epoch - 354ms/step\n",
            "Epoch 20/1000\n",
            "20 Score: 0.672, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.5281 - accuracy: 0.7340 - val_loss: 0.9503 - val_accuracy: 0.6720 - 17s/epoch - 354ms/step\n",
            "Epoch 21/1000\n",
            "21 Score: 0.661, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.4719 - accuracy: 0.7401 - val_loss: 0.9551 - val_accuracy: 0.6613 - 17s/epoch - 355ms/step\n",
            "Epoch 22/1000\n",
            "22 Score: 0.683, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.4954 - accuracy: 0.7562 - val_loss: 0.9047 - val_accuracy: 0.6828 - 17s/epoch - 360ms/step\n",
            "Epoch 23/1000\n",
            "23 Score: 0.656, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.4859 - accuracy: 0.7623 - val_loss: 0.9986 - val_accuracy: 0.6559 - 17s/epoch - 358ms/step\n",
            "Epoch 24/1000\n",
            "24 Score: 0.667, Best epoch: 15, 0.712\n",
            "47/47 - 16s - loss: 0.4527 - accuracy: 0.7630 - val_loss: 0.9744 - val_accuracy: 0.6667 - 16s/epoch - 351ms/step\n",
            "Epoch 25/1000\n",
            "25 Score: 0.683, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.4258 - accuracy: 0.7791 - val_loss: 0.9645 - val_accuracy: 0.6828 - 17s/epoch - 356ms/step\n",
            "Epoch 26/1000\n",
            "26 Score: 0.659, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.4678 - accuracy: 0.7636 - val_loss: 1.0069 - val_accuracy: 0.6586 - 17s/epoch - 359ms/step\n",
            "Epoch 27/1000\n",
            "27 Score: 0.694, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.4048 - accuracy: 0.7616 - val_loss: 0.9249 - val_accuracy: 0.6935 - 17s/epoch - 356ms/step\n",
            "Epoch 28/1000\n",
            "28 Score: 0.691, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.4114 - accuracy: 0.7731 - val_loss: 0.8842 - val_accuracy: 0.6909 - 17s/epoch - 356ms/step\n",
            "Epoch 29/1000\n",
            "29 Score: 0.680, Best epoch: 15, 0.712\n",
            "47/47 - 18s - loss: 0.4394 - accuracy: 0.7731 - val_loss: 0.9305 - val_accuracy: 0.6801 - 18s/epoch - 392ms/step\n",
            "Epoch 30/1000\n",
            "30 Score: 0.685, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.3750 - accuracy: 0.7778 - val_loss: 0.9362 - val_accuracy: 0.6855 - 17s/epoch - 354ms/step\n",
            "Epoch 31/1000\n",
            "31 Score: 0.661, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.4811 - accuracy: 0.7758 - val_loss: 0.9607 - val_accuracy: 0.6613 - 17s/epoch - 359ms/step\n",
            "Epoch 32/1000\n",
            "32 Score: 0.704, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.3845 - accuracy: 0.7650 - val_loss: 0.9507 - val_accuracy: 0.7043 - 17s/epoch - 355ms/step\n",
            "Epoch 33/1000\n",
            "33 Score: 0.642, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.4311 - accuracy: 0.7717 - val_loss: 1.0900 - val_accuracy: 0.6425 - 17s/epoch - 356ms/step\n",
            "Epoch 34/1000\n",
            "34 Score: 0.694, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.4086 - accuracy: 0.7697 - val_loss: 0.9717 - val_accuracy: 0.6935 - 17s/epoch - 355ms/step\n",
            "Epoch 35/1000\n",
            "35 Score: 0.683, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.3748 - accuracy: 0.7933 - val_loss: 0.9882 - val_accuracy: 0.6828 - 17s/epoch - 359ms/step\n",
            "Epoch 36/1000\n",
            "36 Score: 0.677, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.4076 - accuracy: 0.7791 - val_loss: 0.9657 - val_accuracy: 0.6774 - 17s/epoch - 357ms/step\n",
            "Epoch 37/1000\n",
            "37 Score: 0.688, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.3851 - accuracy: 0.8054 - val_loss: 0.9566 - val_accuracy: 0.6882 - 17s/epoch - 356ms/step\n",
            "Epoch 38/1000\n",
            "38 Score: 0.699, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.4048 - accuracy: 0.7980 - val_loss: 0.9048 - val_accuracy: 0.6989 - 17s/epoch - 359ms/step\n",
            "Epoch 39/1000\n",
            "39 Score: 0.675, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.3894 - accuracy: 0.7926 - val_loss: 0.9793 - val_accuracy: 0.6747 - 17s/epoch - 358ms/step\n",
            "Epoch 40/1000\n",
            "40 Score: 0.677, Best epoch: 15, 0.712\n",
            "Reducing learning rate from 0.0010000000474974513 to 0.00010000000474974513\n",
            "47/47 - 17s - loss: 0.3939 - accuracy: 0.7912 - val_loss: 0.9655 - val_accuracy: 0.6774 - 17s/epoch - 353ms/step\n",
            "Epoch 41/1000\n",
            "41 Score: 0.691, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.5777 - accuracy: 0.7461 - val_loss: 0.9232 - val_accuracy: 0.6909 - 17s/epoch - 354ms/step\n",
            "Epoch 42/1000\n",
            "42 Score: 0.694, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.4836 - accuracy: 0.7609 - val_loss: 0.9322 - val_accuracy: 0.6935 - 17s/epoch - 353ms/step\n",
            "Epoch 43/1000\n",
            "43 Score: 0.683, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.5334 - accuracy: 0.7468 - val_loss: 0.9359 - val_accuracy: 0.6828 - 17s/epoch - 355ms/step\n",
            "Epoch 44/1000\n",
            "44 Score: 0.688, Best epoch: 15, 0.712\n",
            "47/47 - 18s - loss: 0.5151 - accuracy: 0.7367 - val_loss: 0.9316 - val_accuracy: 0.6882 - 18s/epoch - 389ms/step\n",
            "Epoch 45/1000\n",
            "45 Score: 0.680, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.4734 - accuracy: 0.7448 - val_loss: 0.9256 - val_accuracy: 0.6801 - 17s/epoch - 351ms/step\n",
            "Epoch 46/1000\n",
            "46 Score: 0.691, Best epoch: 15, 0.712\n",
            "47/47 - 16s - loss: 0.5101 - accuracy: 0.7542 - val_loss: 0.9221 - val_accuracy: 0.6909 - 16s/epoch - 350ms/step\n",
            "Epoch 47/1000\n",
            "47 Score: 0.691, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.4640 - accuracy: 0.7495 - val_loss: 0.9177 - val_accuracy: 0.6909 - 17s/epoch - 353ms/step\n",
            "Epoch 48/1000\n",
            "48 Score: 0.696, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.4571 - accuracy: 0.7549 - val_loss: 0.9131 - val_accuracy: 0.6962 - 17s/epoch - 351ms/step\n",
            "Epoch 49/1000\n",
            "49 Score: 0.696, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.4823 - accuracy: 0.7690 - val_loss: 0.9050 - val_accuracy: 0.6962 - 17s/epoch - 354ms/step\n",
            "Epoch 50/1000\n",
            "50 Score: 0.699, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.4380 - accuracy: 0.7609 - val_loss: 0.9073 - val_accuracy: 0.6989 - 17s/epoch - 356ms/step\n",
            "Epoch 51/1000\n",
            "51 Score: 0.694, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.4465 - accuracy: 0.7690 - val_loss: 0.9114 - val_accuracy: 0.6935 - 17s/epoch - 352ms/step\n",
            "Epoch 52/1000\n",
            "52 Score: 0.691, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.4921 - accuracy: 0.7751 - val_loss: 0.9207 - val_accuracy: 0.6909 - 17s/epoch - 356ms/step\n",
            "Epoch 53/1000\n",
            "53 Score: 0.685, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.5056 - accuracy: 0.7576 - val_loss: 0.9204 - val_accuracy: 0.6855 - 17s/epoch - 356ms/step\n",
            "Epoch 54/1000\n",
            "54 Score: 0.680, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.4644 - accuracy: 0.7616 - val_loss: 0.9176 - val_accuracy: 0.6801 - 17s/epoch - 352ms/step\n",
            "Epoch 55/1000\n",
            "55 Score: 0.691, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.4743 - accuracy: 0.7529 - val_loss: 0.9171 - val_accuracy: 0.6909 - 17s/epoch - 361ms/step\n",
            "Epoch 56/1000\n",
            "56 Score: 0.688, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.4545 - accuracy: 0.7562 - val_loss: 0.9182 - val_accuracy: 0.6882 - 17s/epoch - 356ms/step\n",
            "Epoch 57/1000\n",
            "57 Score: 0.683, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.4313 - accuracy: 0.7684 - val_loss: 0.9205 - val_accuracy: 0.6828 - 17s/epoch - 352ms/step\n",
            "Epoch 58/1000\n",
            "58 Score: 0.696, Best epoch: 15, 0.712\n",
            "47/47 - 18s - loss: 0.4404 - accuracy: 0.7596 - val_loss: 0.9167 - val_accuracy: 0.6962 - 18s/epoch - 384ms/step\n",
            "Epoch 59/1000\n",
            "59 Score: 0.688, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.4431 - accuracy: 0.7690 - val_loss: 0.9099 - val_accuracy: 0.6882 - 17s/epoch - 353ms/step\n",
            "Epoch 60/1000\n",
            "60 Score: 0.702, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.4515 - accuracy: 0.7764 - val_loss: 0.9086 - val_accuracy: 0.7016 - 17s/epoch - 354ms/step\n",
            "Epoch 61/1000\n",
            "61 Score: 0.704, Best epoch: 15, 0.712\n",
            "47/47 - 17s - loss: 0.4189 - accuracy: 0.7764 - val_loss: 0.9102 - val_accuracy: 0.7043 - 17s/epoch - 354ms/step\n",
            "Epoch 62/1000\n",
            "62 Best Score: improved from 0.712 to 0.715\n",
            "47/47 - 17s - loss: 0.4127 - accuracy: 0.7852 - val_loss: 0.9093 - val_accuracy: 0.7151 - 17s/epoch - 366ms/step\n",
            "Epoch 63/1000\n",
            "63 Score: 0.715, Best epoch: 62, 0.715\n",
            "47/47 - 17s - loss: 0.4716 - accuracy: 0.7731 - val_loss: 0.8985 - val_accuracy: 0.7151 - 17s/epoch - 353ms/step\n",
            "Epoch 64/1000\n",
            "64 Score: 0.704, Best epoch: 62, 0.715\n",
            "47/47 - 17s - loss: 0.4350 - accuracy: 0.7731 - val_loss: 0.9027 - val_accuracy: 0.7043 - 17s/epoch - 353ms/step\n",
            "Epoch 65/1000\n",
            "65 Score: 0.710, Best epoch: 62, 0.715\n",
            "47/47 - 17s - loss: 0.4418 - accuracy: 0.7616 - val_loss: 0.9081 - val_accuracy: 0.7097 - 17s/epoch - 353ms/step\n",
            "Epoch 66/1000\n",
            "66 Score: 0.696, Best epoch: 62, 0.715\n",
            "47/47 - 16s - loss: 0.4223 - accuracy: 0.7697 - val_loss: 0.9167 - val_accuracy: 0.6962 - 16s/epoch - 349ms/step\n",
            "Epoch 67/1000\n",
            "67 Score: 0.694, Best epoch: 62, 0.715\n",
            "47/47 - 16s - loss: 0.4046 - accuracy: 0.7805 - val_loss: 0.9094 - val_accuracy: 0.6935 - 16s/epoch - 351ms/step\n",
            "Epoch 68/1000\n",
            "68 Score: 0.699, Best epoch: 62, 0.715\n",
            "47/47 - 17s - loss: 0.4008 - accuracy: 0.7818 - val_loss: 0.9052 - val_accuracy: 0.6989 - 17s/epoch - 353ms/step\n",
            "Epoch 69/1000\n",
            "69 Score: 0.699, Best epoch: 62, 0.715\n",
            "47/47 - 17s - loss: 0.4138 - accuracy: 0.7704 - val_loss: 0.9036 - val_accuracy: 0.6989 - 17s/epoch - 351ms/step\n",
            "Epoch 70/1000\n",
            "70 Score: 0.712, Best epoch: 62, 0.715\n",
            "47/47 - 16s - loss: 0.3832 - accuracy: 0.7852 - val_loss: 0.8893 - val_accuracy: 0.7124 - 16s/epoch - 351ms/step\n",
            "Epoch 71/1000\n",
            "71 Score: 0.688, Best epoch: 62, 0.715\n",
            "47/47 - 17s - loss: 0.4084 - accuracy: 0.7751 - val_loss: 0.8983 - val_accuracy: 0.6882 - 17s/epoch - 356ms/step\n",
            "Epoch 72/1000\n",
            "72 Score: 0.699, Best epoch: 62, 0.715\n",
            "47/47 - 18s - loss: 0.3841 - accuracy: 0.7960 - val_loss: 0.8936 - val_accuracy: 0.6989 - 18s/epoch - 385ms/step\n",
            "Epoch 73/1000\n",
            "73 Score: 0.712, Best epoch: 62, 0.715\n",
            "47/47 - 17s - loss: 0.4069 - accuracy: 0.7737 - val_loss: 0.8963 - val_accuracy: 0.7124 - 17s/epoch - 353ms/step\n",
            "Epoch 74/1000\n",
            "74 Score: 0.707, Best epoch: 62, 0.715\n",
            "47/47 - 17s - loss: 0.4216 - accuracy: 0.7785 - val_loss: 0.9003 - val_accuracy: 0.7070 - 17s/epoch - 352ms/step\n",
            "Epoch 75/1000\n",
            "75 Score: 0.707, Best epoch: 62, 0.715\n",
            "47/47 - 17s - loss: 0.3952 - accuracy: 0.7852 - val_loss: 0.9030 - val_accuracy: 0.7070 - 17s/epoch - 354ms/step\n",
            "Epoch 76/1000\n",
            "76 Score: 0.704, Best epoch: 62, 0.715\n",
            "47/47 - 17s - loss: 0.3806 - accuracy: 0.7825 - val_loss: 0.8947 - val_accuracy: 0.7043 - 17s/epoch - 355ms/step\n",
            "Epoch 77/1000\n",
            "77 Score: 0.704, Best epoch: 62, 0.715\n",
            "47/47 - 17s - loss: 0.4258 - accuracy: 0.7852 - val_loss: 0.8980 - val_accuracy: 0.7043 - 17s/epoch - 351ms/step\n",
            "Epoch 78/1000\n",
            "78 Score: 0.707, Best epoch: 62, 0.715\n",
            "47/47 - 16s - loss: 0.3766 - accuracy: 0.7825 - val_loss: 0.8893 - val_accuracy: 0.7070 - 16s/epoch - 348ms/step\n",
            "Epoch 79/1000\n",
            "79 Score: 0.710, Best epoch: 62, 0.715\n",
            "47/47 - 16s - loss: 0.3711 - accuracy: 0.7953 - val_loss: 0.8880 - val_accuracy: 0.7097 - 16s/epoch - 348ms/step\n",
            "Epoch 80/1000\n",
            "80 Score: 0.704, Best epoch: 62, 0.715\n",
            "47/47 - 17s - loss: 0.3570 - accuracy: 0.7886 - val_loss: 0.8887 - val_accuracy: 0.7043 - 17s/epoch - 353ms/step\n",
            "Epoch 81/1000\n",
            "81 Score: 0.707, Best epoch: 62, 0.715\n",
            "47/47 - 16s - loss: 0.3825 - accuracy: 0.7825 - val_loss: 0.8837 - val_accuracy: 0.7070 - 16s/epoch - 348ms/step\n",
            "Epoch 82/1000\n",
            "82 Score: 0.707, Best epoch: 62, 0.715\n",
            "47/47 - 16s - loss: 0.3926 - accuracy: 0.7899 - val_loss: 0.8916 - val_accuracy: 0.7070 - 16s/epoch - 348ms/step\n",
            "Epoch 83/1000\n",
            "83 Score: 0.696, Best epoch: 62, 0.715\n",
            "47/47 - 16s - loss: 0.3998 - accuracy: 0.7973 - val_loss: 0.8898 - val_accuracy: 0.6962 - 16s/epoch - 348ms/step\n",
            "Epoch 84/1000\n",
            "84 Score: 0.704, Best epoch: 62, 0.715\n",
            "47/47 - 17s - loss: 0.3831 - accuracy: 0.7677 - val_loss: 0.8849 - val_accuracy: 0.7043 - 17s/epoch - 352ms/step\n",
            "Epoch 85/1000\n",
            "85 Score: 0.712, Best epoch: 62, 0.715\n",
            "47/47 - 16s - loss: 0.3605 - accuracy: 0.7899 - val_loss: 0.8840 - val_accuracy: 0.7124 - 16s/epoch - 349ms/step\n",
            "Epoch 86/1000\n",
            "86 Score: 0.710, Best epoch: 62, 0.715\n",
            "47/47 - 17s - loss: 0.3868 - accuracy: 0.7899 - val_loss: 0.8896 - val_accuracy: 0.7097 - 17s/epoch - 369ms/step\n",
            "Epoch 87/1000\n",
            "87 Score: 0.710, Best epoch: 62, 0.715\n",
            "Reducing learning rate from 0.00010000000474974513 to 1.0000000474974514e-05\n",
            "47/47 - 16s - loss: 0.3812 - accuracy: 0.8027 - val_loss: 0.8798 - val_accuracy: 0.7097 - 16s/epoch - 351ms/step\n",
            "Epoch 88/1000\n",
            "88 Best Score: improved from 0.715 to 0.723\n",
            "47/47 - 17s - loss: 0.4132 - accuracy: 0.7697 - val_loss: 0.9065 - val_accuracy: 0.7231 - 17s/epoch - 359ms/step\n",
            "Epoch 89/1000\n",
            "89 Score: 0.723, Best epoch: 88, 0.723\n",
            "47/47 - 16s - loss: 0.4230 - accuracy: 0.7643 - val_loss: 0.9046 - val_accuracy: 0.7231 - 16s/epoch - 348ms/step\n",
            "Epoch 90/1000\n",
            "90 Score: 0.723, Best epoch: 88, 0.723\n",
            "47/47 - 16s - loss: 0.4141 - accuracy: 0.7798 - val_loss: 0.9045 - val_accuracy: 0.7231 - 16s/epoch - 348ms/step\n",
            "Epoch 91/1000\n",
            "91 Score: 0.723, Best epoch: 88, 0.723\n",
            "47/47 - 16s - loss: 0.4326 - accuracy: 0.7737 - val_loss: 0.9048 - val_accuracy: 0.7231 - 16s/epoch - 343ms/step\n",
            "Epoch 92/1000\n",
            "92 Score: 0.723, Best epoch: 88, 0.723\n",
            "47/47 - 16s - loss: 0.4302 - accuracy: 0.7508 - val_loss: 0.9036 - val_accuracy: 0.7231 - 16s/epoch - 348ms/step\n",
            "Epoch 93/1000\n",
            "93 Score: 0.723, Best epoch: 88, 0.723\n",
            "47/47 - 16s - loss: 0.4094 - accuracy: 0.7811 - val_loss: 0.9018 - val_accuracy: 0.7231 - 16s/epoch - 350ms/step\n",
            "Epoch 94/1000\n",
            "94 Score: 0.723, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.4343 - accuracy: 0.7832 - val_loss: 0.9014 - val_accuracy: 0.7231 - 17s/epoch - 351ms/step\n",
            "Epoch 95/1000\n",
            "95 Score: 0.723, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.4516 - accuracy: 0.7758 - val_loss: 0.9023 - val_accuracy: 0.7231 - 17s/epoch - 358ms/step\n",
            "Epoch 96/1000\n",
            "96 Score: 0.723, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.4221 - accuracy: 0.7764 - val_loss: 0.8998 - val_accuracy: 0.7231 - 17s/epoch - 357ms/step\n",
            "Epoch 97/1000\n",
            "97 Score: 0.723, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.3989 - accuracy: 0.7892 - val_loss: 0.8995 - val_accuracy: 0.7231 - 17s/epoch - 353ms/step\n",
            "Epoch 98/1000\n",
            "98 Score: 0.723, Best epoch: 88, 0.723\n",
            "47/47 - 16s - loss: 0.4358 - accuracy: 0.7710 - val_loss: 0.8995 - val_accuracy: 0.7231 - 16s/epoch - 351ms/step\n",
            "Epoch 99/1000\n",
            "99 Score: 0.720, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.4465 - accuracy: 0.7670 - val_loss: 0.8977 - val_accuracy: 0.7204 - 17s/epoch - 356ms/step\n",
            "Epoch 100/1000\n",
            "100 Score: 0.723, Best epoch: 88, 0.723\n",
            "47/47 - 19s - loss: 0.4115 - accuracy: 0.7785 - val_loss: 0.8980 - val_accuracy: 0.7231 - 19s/epoch - 394ms/step\n",
            "Epoch 101/1000\n",
            "101 Score: 0.720, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.4076 - accuracy: 0.7899 - val_loss: 0.8978 - val_accuracy: 0.7204 - 17s/epoch - 358ms/step\n",
            "Epoch 102/1000\n",
            "102 Score: 0.715, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.4330 - accuracy: 0.7980 - val_loss: 0.8992 - val_accuracy: 0.7151 - 17s/epoch - 355ms/step\n",
            "Epoch 103/1000\n",
            "103 Score: 0.715, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.4079 - accuracy: 0.7657 - val_loss: 0.8993 - val_accuracy: 0.7151 - 17s/epoch - 358ms/step\n",
            "Epoch 104/1000\n",
            "104 Score: 0.715, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.3970 - accuracy: 0.7818 - val_loss: 0.8987 - val_accuracy: 0.7151 - 17s/epoch - 355ms/step\n",
            "Epoch 105/1000\n",
            "105 Score: 0.718, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.4125 - accuracy: 0.7778 - val_loss: 0.8999 - val_accuracy: 0.7177 - 17s/epoch - 356ms/step\n",
            "Epoch 106/1000\n",
            "106 Score: 0.715, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.4013 - accuracy: 0.7791 - val_loss: 0.8983 - val_accuracy: 0.7151 - 17s/epoch - 354ms/step\n",
            "Epoch 107/1000\n",
            "107 Score: 0.712, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.4249 - accuracy: 0.7859 - val_loss: 0.8961 - val_accuracy: 0.7124 - 17s/epoch - 358ms/step\n",
            "Epoch 108/1000\n",
            "108 Score: 0.710, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.4020 - accuracy: 0.7785 - val_loss: 0.8962 - val_accuracy: 0.7097 - 17s/epoch - 352ms/step\n",
            "Epoch 109/1000\n",
            "109 Score: 0.710, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.3918 - accuracy: 0.7744 - val_loss: 0.8982 - val_accuracy: 0.7097 - 17s/epoch - 358ms/step\n",
            "Epoch 110/1000\n",
            "110 Score: 0.712, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.4081 - accuracy: 0.7879 - val_loss: 0.8991 - val_accuracy: 0.7124 - 17s/epoch - 356ms/step\n",
            "Epoch 111/1000\n",
            "111 Score: 0.712, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.4075 - accuracy: 0.7697 - val_loss: 0.8980 - val_accuracy: 0.7124 - 17s/epoch - 355ms/step\n",
            "Epoch 112/1000\n",
            "112 Score: 0.707, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.3970 - accuracy: 0.7751 - val_loss: 0.8990 - val_accuracy: 0.7070 - 17s/epoch - 353ms/step\n",
            "Epoch 113/1000\n",
            "113 Score: 0.704, Best epoch: 88, 0.723\n",
            "Reducing learning rate from 1.0000000656873453e-05 to 1.0000000656873453e-06\n",
            "47/47 - 17s - loss: 0.3917 - accuracy: 0.7906 - val_loss: 0.8980 - val_accuracy: 0.7043 - 17s/epoch - 357ms/step\n",
            "Epoch 114/1000\n",
            "114 Score: 0.720, Best epoch: 88, 0.723\n",
            "47/47 - 18s - loss: 0.4265 - accuracy: 0.7906 - val_loss: 0.9064 - val_accuracy: 0.7204 - 18s/epoch - 382ms/step\n",
            "Epoch 115/1000\n",
            "115 Score: 0.718, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.4239 - accuracy: 0.7731 - val_loss: 0.9064 - val_accuracy: 0.7177 - 17s/epoch - 358ms/step\n",
            "Epoch 116/1000\n",
            "116 Score: 0.720, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.4301 - accuracy: 0.7751 - val_loss: 0.9045 - val_accuracy: 0.7204 - 17s/epoch - 359ms/step\n",
            "Epoch 117/1000\n",
            "117 Score: 0.720, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.4018 - accuracy: 0.7798 - val_loss: 0.9028 - val_accuracy: 0.7204 - 17s/epoch - 355ms/step\n",
            "Epoch 118/1000\n",
            "118 Score: 0.720, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.4054 - accuracy: 0.7906 - val_loss: 0.9029 - val_accuracy: 0.7204 - 17s/epoch - 357ms/step\n",
            "Epoch 119/1000\n",
            "119 Score: 0.720, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.3996 - accuracy: 0.7751 - val_loss: 0.9034 - val_accuracy: 0.7204 - 17s/epoch - 353ms/step\n",
            "Epoch 120/1000\n",
            "120 Score: 0.720, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.3827 - accuracy: 0.7852 - val_loss: 0.9043 - val_accuracy: 0.7204 - 17s/epoch - 353ms/step\n",
            "Epoch 121/1000\n",
            "121 Score: 0.720, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.3704 - accuracy: 0.7892 - val_loss: 0.9033 - val_accuracy: 0.7204 - 17s/epoch - 358ms/step\n",
            "Epoch 122/1000\n",
            "122 Score: 0.720, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.4371 - accuracy: 0.7785 - val_loss: 0.9054 - val_accuracy: 0.7204 - 17s/epoch - 354ms/step\n",
            "Epoch 123/1000\n",
            "123 Score: 0.720, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.3860 - accuracy: 0.7859 - val_loss: 0.9063 - val_accuracy: 0.7204 - 17s/epoch - 354ms/step\n",
            "Epoch 124/1000\n",
            "124 Score: 0.720, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.4340 - accuracy: 0.7845 - val_loss: 0.9055 - val_accuracy: 0.7204 - 17s/epoch - 353ms/step\n",
            "Epoch 125/1000\n",
            "125 Score: 0.718, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.4053 - accuracy: 0.7771 - val_loss: 0.9058 - val_accuracy: 0.7177 - 17s/epoch - 356ms/step\n",
            "Epoch 126/1000\n",
            "126 Score: 0.720, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.4073 - accuracy: 0.7872 - val_loss: 0.9036 - val_accuracy: 0.7204 - 17s/epoch - 359ms/step\n",
            "Epoch 127/1000\n",
            "127 Score: 0.720, Best epoch: 88, 0.723\n",
            "47/47 - 16s - loss: 0.4143 - accuracy: 0.7838 - val_loss: 0.9019 - val_accuracy: 0.7204 - 16s/epoch - 349ms/step\n",
            "Epoch 128/1000\n",
            "128 Score: 0.720, Best epoch: 88, 0.723\n",
            "47/47 - 19s - loss: 0.4162 - accuracy: 0.7778 - val_loss: 0.9029 - val_accuracy: 0.7204 - 19s/epoch - 413ms/step\n",
            "Epoch 129/1000\n",
            "129 Score: 0.720, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.4199 - accuracy: 0.7785 - val_loss: 0.9046 - val_accuracy: 0.7204 - 17s/epoch - 355ms/step\n",
            "Epoch 130/1000\n",
            "130 Score: 0.720, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.4031 - accuracy: 0.7811 - val_loss: 0.9043 - val_accuracy: 0.7204 - 17s/epoch - 353ms/step\n",
            "Epoch 131/1000\n",
            "131 Score: 0.720, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.4112 - accuracy: 0.7818 - val_loss: 0.9050 - val_accuracy: 0.7204 - 17s/epoch - 354ms/step\n",
            "Epoch 132/1000\n",
            "132 Score: 0.718, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.4031 - accuracy: 0.7805 - val_loss: 0.9072 - val_accuracy: 0.7177 - 17s/epoch - 358ms/step\n",
            "Epoch 133/1000\n",
            "133 Score: 0.718, Best epoch: 88, 0.723\n",
            "47/47 - 16s - loss: 0.4453 - accuracy: 0.7710 - val_loss: 0.9040 - val_accuracy: 0.7177 - 16s/epoch - 351ms/step\n",
            "Epoch 134/1000\n",
            "134 Score: 0.720, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.4160 - accuracy: 0.7785 - val_loss: 0.9025 - val_accuracy: 0.7204 - 17s/epoch - 356ms/step\n",
            "Epoch 135/1000\n",
            "135 Score: 0.720, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.4338 - accuracy: 0.7791 - val_loss: 0.9021 - val_accuracy: 0.7204 - 17s/epoch - 354ms/step\n",
            "Epoch 136/1000\n",
            "136 Score: 0.720, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.4123 - accuracy: 0.7778 - val_loss: 0.9028 - val_accuracy: 0.7204 - 17s/epoch - 355ms/step\n",
            "Epoch 137/1000\n",
            "137 Score: 0.720, Best epoch: 88, 0.723\n",
            "47/47 - 17s - loss: 0.4389 - accuracy: 0.7737 - val_loss: 0.9042 - val_accuracy: 0.7204 - 17s/epoch - 354ms/step\n",
            "Epoch 138/1000\n",
            "138 Score: 0.720, Best epoch: 88, 0.723\n",
            "Stopping...\n",
            "47/47 - 17s - loss: 0.3995 - accuracy: 0.7845 - val_loss: 0.9023 - val_accuracy: 0.7204 - 17s/epoch - 356ms/step\n"
          ]
        }
      ],
      "source": [
        "#Train\n",
        "log(f\"Training fold {k}...\")\n",
        "model = create_model(size, y_train.shape[1])\n",
        "train_gen= DataGenerator(x_train, y_train, batch_size=batch_size)\n",
        "val_gen= DataGenerator(x_test, y_test, batch_size=batch_size, mode=\"val\")\n",
        "mc = MetricCallback(x_test, y_test, patience=50)\n",
        "logger = CSVLogger(base+'train.csv')\n",
        "callbacks = [mc, logger]\n",
        "weight = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
        "weight = dict(zip(np.unique(y), weight))\n",
        "history = model.fit(train_gen, validation_data=val_gen, epochs=1000, callbacks =callbacks, verbose=2, class_weight=weight) #, workers=multiprocessing.cpu_count(), use_multiprocessing=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "qrYuVHAzfBSe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7f9901f-86eb-42c0-b27c-7892a9d4d578"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "372/372 [==============================] - 3s 7ms/step\n",
            "Precision: 0.72, Recall: 0.72, Micro F1: 0.72\n",
            "Precision: 0.76, Recall: 0.72, Weighted F1: 0.72\n",
            "Precision: 0.52, Recall: 0.62, Macro F1: 0.54\n",
            "Confusion Matrix:\n",
            "0 arrow [('arrow', 2), ('light', 1)]\n",
            "1 button [('button', 8), ('light', 2), ('remove', 1)]\n",
            "2 dropdown [('dropdown', 4), ('icon', 1), ('remove', 1)]\n",
            "3 icon [('arrow', 2), ('icon', 9), ('radio button', 1), ('remove', 1)]\n",
            "4 knob [('knob', 135), ('remove', 1)]\n",
            "5 light [('button', 2), ('light', 1)]\n",
            "6 meter [('arrow', 1), ('meter', 3), ('remove', 1)]\n",
            "7 multiple elements [('meter', 1), ('multiple elements', 3), ('radio button', 1)]\n",
            "8 multiple knobs [('knob', 1), ('multiple knobs', 4), ('remove', 1)]\n",
            "9 needle [('needle', 35)]\n",
            "10 non-interactive [('arrow', 3), ('button', 2), ('dropdown', 4), ('icon', 3), ('knob', 1), ('meter', 5), ('multiple elements', 2), ('needle', 1), ('non-interactive', 36), ('radio button', 2), ('remove', 17), ('slider', 1), ('switch', 1)]\n",
            "11 radio button [('button', 1), ('needle', 1), ('radio button', 5)]\n",
            "12 remove [('arrow', 1), ('button', 2), ('dropdown', 1), ('icon', 7), ('knob', 2), ('light', 1), ('meter', 1), ('needle', 11), ('non-interactive', 7), ('remove', 22), ('slider', 2), ('switch', 1)]\n",
            "13 slider [('arrow', 1), ('icon', 1), ('meter', 1), ('slider', 1)]\n",
            "14 switch [('button', 1), ('switch', 1)]\n"
          ]
        }
      ],
      "source": [
        "#Predict\n",
        "mc.restore()\n",
        "pred_gen= DataGenerator(x_test, mode=\"predict\")\n",
        "preds = model.predict(pred_gen)\n",
        "score = precision_recall_fscore_support(y_test.argmax(-1), preds.argmax(-1), average='micro')\n",
        "print(f\"Micro Precision: {score[0]:.2f}, Recall: {score[1]:.2f}, F1: {score[2]:.2f}\")\n",
        "score = precision_recall_fscore_support(y_test.argmax(-1), preds.argmax(-1), average='weighted')\n",
        "print(f\"Weighted Precision: {score[0]:.2f}, Recall: {score[1]:.2f}, F1: {score[2]:.2f}\")\n",
        "score = precision_recall_fscore_support(y_test.argmax(-1), preds.argmax(-1), average='macro')\n",
        "print(f\"Macro Precision: {score[0]:.2f}, Recall: {score[1]:.2f}, F1: {score[2]:.2f}\")\n",
        "matrix = confusion_matrix(y_test.argmax(-1), preds.argmax(-1))\n",
        "print(\"Confusion Matrix:\")\n",
        "for i,m in enumerate(matrix):\n",
        "  row = [(le.classes_[j], k) for j, k in enumerate(m) if k>0]\n",
        "  print(i, le.classes_[i], row)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#End\n",
        "now = datetime.now()\n",
        "date_time = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
        "log(f\"Ending at: {date_time}\")\n",
        "t_finish = time.time()\n",
        "total_time = (t_finish-t_start)/60\n",
        "log(f\"It took {total_time:.2f} minutes\")\n",
        "time.sleep(1)\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "0qnKz5UYol16",
        "outputId": "f8b8cd46-1ea0-43b9-d9c0-683c64eb5947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ending at: 12/05/2022, 17:28:17\n",
            "It took 50.67 minutes\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGrn/iT/IwkQnSbZj5Qkn3"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}